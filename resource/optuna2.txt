/home/duhuaiyu/anaconda3/envs/pytroch11/bin/python /home/duhuaiyu/PycharmProjects/Kof97/optunaExec.py
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  "Distutils was imported before Setuptools. This usage is discouraged "
env_id:3UGF21R8TD47HL7
env_id:K8KIE42H1WQP6UW
env_id:KWNIJUW36UY23A2
env_id:FDRNDVD0XFDSCTW
env_id:83DNVEA6U60FJ18
env_id:MA4ZJNLHY4BFONZ
env_id:WBPS4B08K22SKDF
env_id:UHZQVNO2V4C1API
env_id:1J0YZCZ66KBAP2P
env_id:S4R11YYLB2KJ043
env_id:WQ8UNQ9IDISNB5V
env_id:5ZYVJRZLYQOU0TF
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> nil\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xecb5cb8\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xe2ac708\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xec08aa8\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xdc95cd8\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xe7df6b8\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xe94b618\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xf1f6668\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xd3708c8\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xeed8a58\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xedc8b58\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xf0ebb68\n'
b'\x1b[1;36m[MAME]\x1b[0m> sol.lua_engine::addr_space: 0xe28f4a8\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> \x1b[1;36m[MAME]\x1b[0m> RGB32 - 32bpp 8-8-8 RGB\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 320\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
b'\x1b[1;36m[MAME]\x1b[0m> 224\n'
[I 2022-04-25 15:16:52,609] A new study created in memory with name: no-name-2ae239cf-ffa2-46b8-9eaf-590047550b33
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 95666, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_1
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 842        |
|    ep_rew_mean     | -174.56226 |
| time/              |            |
|    fps             | 512        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 861           |
|    ep_rew_mean          | -149.60484    |
| time/                   |               |
|    fps                  | 509           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.6004924e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.174         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000738     |
|    learning_rate        | 2.82e-05      |
|    loss                 | 54.5          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.2e-05      |
|    value_loss           | 109           |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 829            |
|    ep_rew_mean          | -139.11716     |
| time/                   |                |
|    fps                  | 492            |
|    iterations           | 3              |
|    time_elapsed         | 149            |
|    total_timesteps      | 73728          |
| train/                  |                |
|    approx_kl            | 1.06161075e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.174          |
|    entropy_loss         | -3.89          |
|    explained_variance   | 0.00189        |
|    learning_rate        | 2.82e-05       |
|    loss                 | 60.7           |
|    n_updates            | 20             |
|    policy_gradient_loss | -1.68e-05      |
|    value_loss           | 122            |
--------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 810            |
|    ep_rew_mean          | -135.37512     |
| time/                   |                |
|    fps                  | 491            |
|    iterations           | 4              |
|    time_elapsed         | 200            |
|    total_timesteps      | 98304          |
| train/                  |                |
|    approx_kl            | 1.14467795e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.174          |
|    entropy_loss         | -3.89          |
|    explained_variance   | 0.00194        |
|    learning_rate        | 2.82e-05       |
|    loss                 | 61.3           |
|    n_updates            | 30             |
|    policy_gradient_loss | -1.26e-05      |
|    value_loss           | 123            |
--------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 810         |
|    ep_rew_mean          | -143.13812  |
| time/                   |             |
|    fps                  | 488         |
|    iterations           | 5           |
|    time_elapsed         | 251         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 8.16799e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.174       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.00115     |
|    learning_rate        | 2.82e-05    |
|    loss                 | 52          |
|    n_updates            | 40          |
|    policy_gradient_loss | -1.07e-05   |
|    value_loss           | 104         |
-----------------------------------------
mean_reward
-196.02377
[I 2022-04-25 15:21:37,052] Trial 0 finished with value: -196.02377319335938 and parameters: {'batch_size': 95666, 'gamma': 0.9831602988269198, 'learning_rate': 2.8180840141068102e-05, 'clip_range': 0.17405837857167217, 'gae_lambda': 0.975609844328819}. Best is trial 0 with value: -196.02377319335938.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 73134, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_2
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 863       |
|    ep_rew_mean     | -162.0001 |
| time/              |           |
|    fps             | 528       |
|    iterations      | 1         |
|    time_elapsed    | 46        |
|    total_timesteps | 24576     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 838         |
|    ep_rew_mean          | -161.0567   |
| time/                   |             |
|    fps                  | 512         |
|    iterations           | 2           |
|    time_elapsed         | 95          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 2.74015e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.221       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.0037     |
|    learning_rate        | 2.39e-05    |
|    loss                 | 13.1        |
|    n_updates            | 10          |
|    policy_gradient_loss | -4.18e-05   |
|    value_loss           | 26.2        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 854           |
|    ep_rew_mean          | -148.57483    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.2835836e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.221         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00269      |
|    learning_rate        | 2.39e-05      |
|    loss                 | 11.7          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.35e-05     |
|    value_loss           | 23.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 854           |
|    ep_rew_mean          | -143.59064    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 4             |
|    time_elapsed         | 193           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.6423126e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.221         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00503      |
|    learning_rate        | 2.39e-05      |
|    loss                 | 10.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.73e-05     |
|    value_loss           | 21.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -139.37854    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 5             |
|    time_elapsed         | 241           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.8276964e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.221         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00395      |
|    learning_rate        | 2.39e-05      |
|    loss                 | 10.8          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.78e-05     |
|    value_loss           | 21.7          |
-------------------------------------------
mean_reward
-163.84976
[I 2022-04-25 15:26:11,440] Trial 1 finished with value: -163.84976196289062 and parameters: {'batch_size': 73134, 'gamma': 0.9641699364764384, 'learning_rate': 2.3858652030211467e-05, 'clip_range': 0.22143463105260658, 'gae_lambda': 0.8961514190764548}. Best is trial 1 with value: -163.84976196289062.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 21729, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 2847
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_3
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 774        |
|    ep_rew_mean     | -170.85532 |
| time/              |            |
|    fps             | 509        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 789           |
|    ep_rew_mean          | -165.41534    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.0449382e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.101         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00675      |
|    learning_rate        | 2.05e-05      |
|    loss                 | 8.22          |
|    n_updates            | 10            |
|    policy_gradient_loss | -5.37e-05     |
|    value_loss           | 16.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 770           |
|    ep_rew_mean          | -163.54922    |
| time/                   |               |
|    fps                  | 484           |
|    iterations           | 3             |
|    time_elapsed         | 152           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.8051473e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.101         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00538      |
|    learning_rate        | 2.05e-05      |
|    loss                 | 7.17          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.72e-05     |
|    value_loss           | 16.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 787           |
|    ep_rew_mean          | -161.84795    |
| time/                   |               |
|    fps                  | 485           |
|    iterations           | 4             |
|    time_elapsed         | 202           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.8069012e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.101         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00574      |
|    learning_rate        | 2.05e-05      |
|    loss                 | 11            |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.92e-05     |
|    value_loss           | 19            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 789           |
|    ep_rew_mean          | -156.03949    |
| time/                   |               |
|    fps                  | 485           |
|    iterations           | 5             |
|    time_elapsed         | 253           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.9604931e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.101         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00462      |
|    learning_rate        | 2.05e-05      |
|    loss                 | 7.34          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.65e-05     |
|    value_loss           | 17            |
-------------------------------------------
mean_reward
-217.45366
[I 2022-04-25 15:30:53,822] Trial 2 finished with value: -217.4536590576172 and parameters: {'batch_size': 21729, 'gamma': 0.9067581223579837, 'learning_rate': 2.052581805754462e-05, 'clip_range': 0.10119539382117958, 'gae_lambda': 0.9212005910409717}. Best is trial 1 with value: -163.84976196289062.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 28080, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_4
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 807        |
|    ep_rew_mean     | -172.69441 |
| time/              |            |
|    fps             | 523        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 812           |
|    ep_rew_mean          | -161.29625    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 5.6432327e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.137         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00183      |
|    learning_rate        | 1.42e-05      |
|    loss                 | 54.7          |
|    n_updates            | 10            |
|    policy_gradient_loss | -1.73e-05     |
|    value_loss           | 109           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -167.02531    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.1325016e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.137         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00125      |
|    learning_rate        | 1.42e-05      |
|    loss                 | 42.5          |
|    n_updates            | 20            |
|    policy_gradient_loss | -9.79e-06     |
|    value_loss           | 85            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 831           |
|    ep_rew_mean          | -150.34909    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 4             |
|    time_elapsed         | 194           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 3.0204927e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.137         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00119      |
|    learning_rate        | 1.42e-05      |
|    loss                 | 44.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -5.92e-06     |
|    value_loss           | 89.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 847          |
|    ep_rew_mean          | -157.40552   |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 5            |
|    time_elapsed         | 244          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 3.601114e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.137        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00145     |
|    learning_rate        | 1.42e-05     |
|    loss                 | 49.9         |
|    n_updates            | 40           |
|    policy_gradient_loss | -8.68e-06    |
|    value_loss           | 100          |
------------------------------------------
mean_reward
-132.21237
[I 2022-04-25 15:35:24,257] Trial 3 finished with value: -132.21237182617188 and parameters: {'batch_size': 28080, 'gamma': 0.9783081123370039, 'learning_rate': 1.419357717751883e-05, 'clip_range': 0.13666098101743684, 'gae_lambda': 0.9742776834495588}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 43802, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_5
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 793        |
|    ep_rew_mean     | -152.61946 |
| time/              |            |
|    fps             | 521        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 779           |
|    ep_rew_mean          | -149.1591     |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 8.6429645e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.111         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00357      |
|    learning_rate        | 4.96e-05      |
|    loss                 | 8.47          |
|    n_updates            | 10            |
|    policy_gradient_loss | -9.16e-05     |
|    value_loss           | 17            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 801          |
|    ep_rew_mean          | -156.32274   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 5.329348e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.111        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00183     |
|    learning_rate        | 4.96e-05     |
|    loss                 | 9.06         |
|    n_updates            | 20           |
|    policy_gradient_loss | -4.68e-05    |
|    value_loss           | 18.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -153.67557    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.4485205e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.111         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000549      |
|    learning_rate        | 4.96e-05      |
|    loss                 | 8.03          |
|    n_updates            | 30            |
|    policy_gradient_loss | -4.15e-05     |
|    value_loss           | 16.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 823          |
|    ep_rew_mean          | -160.30666   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 5            |
|    time_elapsed         | 249          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.031487e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.111        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000272    |
|    learning_rate        | 4.96e-05     |
|    loss                 | 7.9          |
|    n_updates            | 40           |
|    policy_gradient_loss | -3.72e-05    |
|    value_loss           | 15.9         |
------------------------------------------
mean_reward
-206.43588
[I 2022-04-25 15:39:52,951] Trial 4 finished with value: -206.43588256835938 and parameters: {'batch_size': 43802, 'gamma': 0.9409410950840491, 'learning_rate': 4.959224663000696e-05, 'clip_range': 0.11091308916536045, 'gae_lambda': 0.8642426673463557}. Best is trial 3 with value: -132.21237182617188.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 31349, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_6
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 865        |
|    ep_rew_mean     | -161.46782 |
| time/              |            |
|    fps             | 511        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -160.5927     |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.2013722e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.355         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00087      |
|    learning_rate        | 7.56e-05      |
|    loss                 | 29.3          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000105     |
|    value_loss           | 59            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 821          |
|    ep_rew_mean          | -158.93602   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 6.160262e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.355        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000261     |
|    learning_rate        | 7.56e-05     |
|    loss                 | 29.2         |
|    n_updates            | 20           |
|    policy_gradient_loss | -4.03e-05    |
|    value_loss           | 58.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -160.55562    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.9105275e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.355         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00179       |
|    learning_rate        | 7.56e-05      |
|    loss                 | 29.8          |
|    n_updates            | 30            |
|    policy_gradient_loss | -4.45e-05     |
|    value_loss           | 60            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 801          |
|    ep_rew_mean          | -154.19334   |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.024719e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.355        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00194      |
|    learning_rate        | 7.56e-05     |
|    loss                 | 25.4         |
|    n_updates            | 40           |
|    policy_gradient_loss | -4.21e-05    |
|    value_loss           | 51.2         |
------------------------------------------
mean_reward
-190.59264
[I 2022-04-25 15:44:29,578] Trial 5 finished with value: -190.59263610839844 and parameters: {'batch_size': 31349, 'gamma': 0.9735136960944475, 'learning_rate': 7.563749853451645e-05, 'clip_range': 0.35541552212362204, 'gae_lambda': 0.9600385365399341}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 98514, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_7
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 773        |
|    ep_rew_mean     | -162.92316 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 788           |
|    ep_rew_mean          | -162.22441    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.0608644e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00096      |
|    learning_rate        | 8.63e-05      |
|    loss                 | 8.78          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000164     |
|    value_loss           | 17.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 797          |
|    ep_rew_mean          | -160.30414   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 2.183127e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.389        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -8.08e-05    |
|    learning_rate        | 8.63e-05     |
|    loss                 | 9.29         |
|    n_updates            | 20           |
|    policy_gradient_loss | -8.1e-05     |
|    value_loss           | 18.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 801           |
|    ep_rew_mean          | -161.8257     |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.6015741e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000943     |
|    learning_rate        | 8.63e-05      |
|    loss                 | 9.01          |
|    n_updates            | 30            |
|    policy_gradient_loss | -6.66e-05     |
|    value_loss           | 18.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -173.44496    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.6355965e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00374       |
|    learning_rate        | 8.63e-05      |
|    loss                 | 9             |
|    n_updates            | 40            |
|    policy_gradient_loss | -5.96e-05     |
|    value_loss           | 18.2          |
-------------------------------------------
mean_reward
-197.28537
[I 2022-04-25 15:49:00,311] Trial 6 finished with value: -197.28536987304688 and parameters: {'batch_size': 98514, 'gamma': 0.9841282888947992, 'learning_rate': 8.625280659645494e-05, 'clip_range': 0.3887592257420064, 'gae_lambda': 0.8510318057669253}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 56036, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_8
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 845        |
|    ep_rew_mean     | -146.66214 |
| time/              |            |
|    fps             | 539        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 834         |
|    ep_rew_mean          | -147.8855   |
| time/                   |             |
|    fps                  | 509         |
|    iterations           | 2           |
|    time_elapsed         | 96          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 8.52119e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.383       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.00183    |
|    learning_rate        | 9.82e-05    |
|    loss                 | 4.45        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00024    |
|    value_loss           | 9.01        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 837           |
|    ep_rew_mean          | -152.9344     |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.1163615e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.383         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000429      |
|    learning_rate        | 9.82e-05      |
|    loss                 | 5.66          |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000113     |
|    value_loss           | 11.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 838           |
|    ep_rew_mean          | -158.37076    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.3685022e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.383         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00501       |
|    learning_rate        | 9.82e-05      |
|    loss                 | 4.68          |
|    n_updates            | 30            |
|    policy_gradient_loss | -9.64e-05     |
|    value_loss           | 9.45          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 825          |
|    ep_rew_mean          | -170.08183   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 246          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.905206e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.383        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00512      |
|    learning_rate        | 9.82e-05     |
|    loss                 | 5.17         |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000101    |
|    value_loss           | 10.4         |
------------------------------------------
mean_reward
-185.7174
[I 2022-04-25 15:53:29,442] Trial 7 finished with value: -185.7174072265625 and parameters: {'batch_size': 56036, 'gamma': 0.9050548266865408, 'learning_rate': 9.815319615854705e-05, 'clip_range': 0.38314672534657557, 'gae_lambda': 0.8120474655315559}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 82156, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_9
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 827        |
|    ep_rew_mean     | -159.38908 |
| time/              |            |
|    fps             | 527        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 846           |
|    ep_rew_mean          | -165.22168    |
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 2             |
|    time_elapsed         | 94            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0318181e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.202         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000155      |
|    learning_rate        | 5.91e-05      |
|    loss                 | 8.72          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000106     |
|    value_loss           | 17.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 861           |
|    ep_rew_mean          | -161.07678    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.9347803e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.202         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000825      |
|    learning_rate        | 5.91e-05      |
|    loss                 | 8.97          |
|    n_updates            | 20            |
|    policy_gradient_loss | -4.59e-05     |
|    value_loss           | 18.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 831           |
|    ep_rew_mean          | -162.29877    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.7343353e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.202         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00386       |
|    learning_rate        | 5.91e-05      |
|    loss                 | 7.64          |
|    n_updates            | 30            |
|    policy_gradient_loss | -5.68e-05     |
|    value_loss           | 15.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 835          |
|    ep_rew_mean          | -157.30482   |
| time/                   |              |
|    fps                  | 503          |
|    iterations           | 5            |
|    time_elapsed         | 244          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 5.683639e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.202        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0068       |
|    learning_rate        | 5.91e-05     |
|    loss                 | 9.22         |
|    n_updates            | 40           |
|    policy_gradient_loss | -3.82e-05    |
|    value_loss           | 18.6         |
------------------------------------------
mean_reward
-147.15813
[I 2022-04-25 15:58:07,060] Trial 8 finished with value: -147.1581268310547 and parameters: {'batch_size': 82156, 'gamma': 0.937017062807873, 'learning_rate': 5.905408650035334e-05, 'clip_range': 0.20182964470004938, 'gae_lambda': 0.8963296118032944}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 39566, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_10
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 803        |
|    ep_rew_mean     | -161.52518 |
| time/              |            |
|    fps             | 505        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 766           |
|    ep_rew_mean          | -147.36278    |
| time/                   |               |
|    fps                  | 489           |
|    iterations           | 2             |
|    time_elapsed         | 100           |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.2049713e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00208      |
|    learning_rate        | 1.45e-05      |
|    loss                 | 10.3          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.79e-05     |
|    value_loss           | 20.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 801          |
|    ep_rew_mean          | -149.22307   |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 3            |
|    time_elapsed         | 150          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 8.273249e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.314        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00148     |
|    learning_rate        | 1.45e-05     |
|    loss                 | 11           |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.47e-05    |
|    value_loss           | 22           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 834           |
|    ep_rew_mean          | -147.39885    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.5275046e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00103      |
|    learning_rate        | 1.45e-05      |
|    loss                 | 9.09          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.18e-05     |
|    value_loss           | 18.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -156.99635   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 6.703825e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.314        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00125      |
|    learning_rate        | 1.45e-05     |
|    loss                 | 9.53         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.21e-05    |
|    value_loss           | 19.1         |
------------------------------------------
mean_reward
-184.63966
[I 2022-04-25 16:02:41,468] Trial 9 finished with value: -184.63966369628906 and parameters: {'batch_size': 39566, 'gamma': 0.9187713150034099, 'learning_rate': 1.4533716367984882e-05, 'clip_range': 0.3137693113146037, 'gae_lambda': 0.9231239461633411}. Best is trial 3 with value: -132.21237182617188.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 15833, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 8743
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_11
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 831        |
|    ep_rew_mean     | -144.58481 |
| time/              |            |
|    fps             | 530        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 822          |
|    ep_rew_mean          | -145.68782   |
| time/                   |              |
|    fps                  | 504          |
|    iterations           | 2            |
|    time_elapsed         | 97           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.623148e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.27         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000698    |
|    learning_rate        | 1.01e-05     |
|    loss                 | 200          |
|    n_updates            | 10           |
|    policy_gradient_loss | -1.22e-05    |
|    value_loss           | 403          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 800           |
|    ep_rew_mean          | -159.4187     |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.0294017e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.27          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000401     |
|    learning_rate        | 1.01e-05      |
|    loss                 | 184           |
|    n_updates            | 20            |
|    policy_gradient_loss | -6.82e-06     |
|    value_loss           | 369           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -153.42398    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 4             |
|    time_elapsed         | 196           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.5970166e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.27          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000427     |
|    learning_rate        | 1.01e-05      |
|    loss                 | 248           |
|    n_updates            | 30            |
|    policy_gradient_loss | -5.81e-06     |
|    value_loss           | 502           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 807          |
|    ep_rew_mean          | -156.35509   |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 2.533239e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.27         |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00025      |
|    learning_rate        | 1.01e-05     |
|    loss                 | 168          |
|    n_updates            | 40           |
|    policy_gradient_loss | -8.27e-06    |
|    value_loss           | 345          |
------------------------------------------
mean_reward
-177.18535
[I 2022-04-25 16:07:17,609] Trial 10 finished with value: -177.1853485107422 and parameters: {'batch_size': 15833, 'gamma': 0.9995143246584367, 'learning_rate': 1.0127019873083764e-05, 'clip_range': 0.2698701237968103, 'gae_lambda': 0.9855321700478381}. Best is trial 3 with value: -132.21237182617188.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 76820, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_12
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 868        |
|    ep_rew_mean     | -179.47166 |
| time/              |            |
|    fps             | 524        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 834          |
|    ep_rew_mean          | -166.06364   |
| time/                   |              |
|    fps                  | 512          |
|    iterations           | 2            |
|    time_elapsed         | 95           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 4.542453e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.177        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00276     |
|    learning_rate        | 4.3e-05      |
|    loss                 | 12.8         |
|    n_updates            | 10           |
|    policy_gradient_loss | -6.84e-05    |
|    value_loss           | 25.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 842           |
|    ep_rew_mean          | -160.74612    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.4115192e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.177         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0015       |
|    learning_rate        | 4.3e-05       |
|    loss                 | 14.5          |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.03e-05     |
|    value_loss           | 29.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 849           |
|    ep_rew_mean          | -159.00699    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 4             |
|    time_elapsed         | 196           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.8051727e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.177         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00148      |
|    learning_rate        | 4.3e-05       |
|    loss                 | 14.9          |
|    n_updates            | 30            |
|    policy_gradient_loss | -3.14e-05     |
|    value_loss           | 30            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 830           |
|    ep_rew_mean          | -157.36185    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.0957744e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.177         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00198      |
|    learning_rate        | 4.3e-05       |
|    loss                 | 15.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.18e-05     |
|    value_loss           | 31.6          |
-------------------------------------------
mean_reward
-176.27959
[I 2022-04-25 16:11:47,214] Trial 11 finished with value: -176.2795867919922 and parameters: {'batch_size': 76820, 'gamma': 0.9432172901533051, 'learning_rate': 4.300120557205226e-05, 'clip_range': 0.1772817824047206, 'gae_lambda': 0.9418714996011689}. Best is trial 3 with value: -132.21237182617188.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 71952, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_13
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 790        |
|    ep_rew_mean     | -167.10594 |
| time/              |            |
|    fps             | 525        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 807          |
|    ep_rew_mean          | -169.52332   |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.518982e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.165        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00286     |
|    learning_rate        | 4.37e-05     |
|    loss                 | 8            |
|    n_updates            | 10           |
|    policy_gradient_loss | -8.54e-05    |
|    value_loss           | 16.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -163.34668    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.7219754e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.165         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00221      |
|    learning_rate        | 4.37e-05      |
|    loss                 | 7.36          |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.7e-05      |
|    value_loss           | 14.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 813          |
|    ep_rew_mean          | -157.57428   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 4            |
|    time_elapsed         | 198          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 4.184064e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.165        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000947    |
|    learning_rate        | 4.37e-05     |
|    loss                 | 7.51         |
|    n_updates            | 30           |
|    policy_gradient_loss | -3.92e-05    |
|    value_loss           | 15.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -153.88887    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.3874996e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.165         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000823      |
|    learning_rate        | 4.37e-05      |
|    loss                 | 7.05          |
|    n_updates            | 40            |
|    policy_gradient_loss | -4.01e-05     |
|    value_loss           | 14.2          |
-------------------------------------------
mean_reward
-237.25594
[I 2022-04-25 16:16:23,300] Trial 12 finished with value: -237.2559356689453 and parameters: {'batch_size': 71952, 'gamma': 0.9282271324972613, 'learning_rate': 4.37455601915999e-05, 'clip_range': 0.16499439107500352, 'gae_lambda': 0.8734646690782204}. Best is trial 3 with value: -132.21237182617188.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 60448, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_14
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 778        |
|    ep_rew_mean     | -144.73058 |
| time/              |            |
|    fps             | 514        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 778           |
|    ep_rew_mean          | -141.94527    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.6930256e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.224         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00142      |
|    learning_rate        | 5.68e-05      |
|    loss                 | 5.89          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000119     |
|    value_loss           | 11.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 804          |
|    ep_rew_mean          | -151.34908   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 3            |
|    time_elapsed         | 149          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.137271e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.224        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000845    |
|    learning_rate        | 5.68e-05     |
|    loss                 | 6.43         |
|    n_updates            | 20           |
|    policy_gradient_loss | -5.82e-05    |
|    value_loss           | 13           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 815          |
|    ep_rew_mean          | -150.57791   |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 4            |
|    time_elapsed         | 200          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.292198e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.224        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000336     |
|    learning_rate        | 5.68e-05     |
|    loss                 | 7.15         |
|    n_updates            | 30           |
|    policy_gradient_loss | -5.1e-05     |
|    value_loss           | 14.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 835          |
|    ep_rew_mean          | -149.41953   |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 5            |
|    time_elapsed         | 250          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 8.464631e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.224        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00119     |
|    learning_rate        | 5.68e-05     |
|    loss                 | 6.87         |
|    n_updates            | 40           |
|    policy_gradient_loss | -4.69e-05    |
|    value_loss           | 13.8         |
------------------------------------------
mean_reward
-291.73474
[I 2022-04-25 16:20:56,098] Trial 13 finished with value: -291.7347412109375 and parameters: {'batch_size': 60448, 'gamma': 0.9578602512036485, 'learning_rate': 5.684821354881482e-05, 'clip_range': 0.22372957480038325, 'gae_lambda': 0.8137957830564891}. Best is trial 3 with value: -132.21237182617188.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 81304, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_15
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 721        |
|    ep_rew_mean     | -161.13846 |
| time/              |            |
|    fps             | 515        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 746           |
|    ep_rew_mean          | -171.44637    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0875859e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.143         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00382      |
|    learning_rate        | 1.67e-05      |
|    loss                 | 8.58          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.93e-05     |
|    value_loss           | 17.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 759          |
|    ep_rew_mean          | -171.03467   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 3            |
|    time_elapsed         | 149          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.031404e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.143        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00207     |
|    learning_rate        | 1.67e-05     |
|    loss                 | 11.3         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.73e-05    |
|    value_loss           | 22.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 789           |
|    ep_rew_mean          | -160.73871    |
| time/                   |               |
|    fps                  | 490           |
|    iterations           | 4             |
|    time_elapsed         | 200           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.8372174e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.143         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00169      |
|    learning_rate        | 1.67e-05      |
|    loss                 | 8.47          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.37e-05     |
|    value_loss           | 17            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 788          |
|    ep_rew_mean          | -155.51488   |
| time/                   |              |
|    fps                  | 491          |
|    iterations           | 5            |
|    time_elapsed         | 250          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.523098e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.143        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00241     |
|    learning_rate        | 1.67e-05     |
|    loss                 | 10.2         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.43e-05    |
|    value_loss           | 20.4         |
------------------------------------------
mean_reward
-104.8857
[I 2022-04-25 16:25:24,493] Trial 14 finished with value: -104.88569641113281 and parameters: {'batch_size': 81304, 'gamma': 0.9290202229267708, 'learning_rate': 1.6732476578962206e-05, 'clip_range': 0.1425845526941551, 'gae_lambda': 0.896609759459815}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 54658, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_16
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 870        |
|    ep_rew_mean     | -148.14459 |
| time/              |            |
|    fps             | 521        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 825            |
|    ep_rew_mean          | -145.07593     |
| time/                   |                |
|    fps                  | 510            |
|    iterations           | 2              |
|    time_elapsed         | 96             |
|    total_timesteps      | 49152          |
| train/                  |                |
|    approx_kl            | 1.00534336e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.136          |
|    entropy_loss         | -3.89          |
|    explained_variance   | 0.00241        |
|    learning_rate        | 1.6e-05        |
|    loss                 | 16.8           |
|    n_updates            | 10             |
|    policy_gradient_loss | -2.9e-05       |
|    value_loss           | 33.7           |
--------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 820         |
|    ep_rew_mean          | -148.70808  |
| time/                   |             |
|    fps                  | 498         |
|    iterations           | 3           |
|    time_elapsed         | 147         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 6.11908e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.136       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.00269     |
|    learning_rate        | 1.6e-05     |
|    loss                 | 17.8        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.16e-05   |
|    value_loss           | 35.7        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 818           |
|    ep_rew_mean          | -144.10551    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.1702955e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.136         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00373       |
|    learning_rate        | 1.6e-05       |
|    loss                 | 17.9          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.03e-05     |
|    value_loss           | 35.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 830           |
|    ep_rew_mean          | -139.36258    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 5.8809142e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.136         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00308       |
|    learning_rate        | 1.6e-05       |
|    loss                 | 19.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.24e-05     |
|    value_loss           | 38.5          |
-------------------------------------------
mean_reward
-217.93623
[I 2022-04-25 16:29:57,438] Trial 15 finished with value: -217.9362335205078 and parameters: {'batch_size': 54658, 'gamma': 0.9567690360640231, 'learning_rate': 1.5963498195150738e-05, 'clip_range': 0.13620324402287795, 'gae_lambda': 0.9458788748708242}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 10388, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 3800
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_17
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 784        |
|    ep_rew_mean     | -155.68343 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 816           |
|    ep_rew_mean          | -149.50957    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.3283724e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.26          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00316      |
|    learning_rate        | 1.12e-05      |
|    loss                 | 6.26          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.63e-05     |
|    value_loss           | 12.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 835           |
|    ep_rew_mean          | -157.09633    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.4472778e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.26          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000984     |
|    learning_rate        | 1.12e-05      |
|    loss                 | 7.2           |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.05e-05     |
|    value_loss           | 13.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 845          |
|    ep_rew_mean          | -152.08989   |
| time/                   |              |
|    fps                  | 503          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 1.621703e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.26         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00402     |
|    learning_rate        | 1.12e-05     |
|    loss                 | 6.26         |
|    n_updates            | 30           |
|    policy_gradient_loss | -2.86e-05    |
|    value_loss           | 12.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 847           |
|    ep_rew_mean          | -154.60985    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.3212752e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.26          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000978      |
|    learning_rate        | 1.12e-05      |
|    loss                 | 6.24          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.87e-05     |
|    value_loss           | 11.9          |
-------------------------------------------
mean_reward
-162.40369
[I 2022-04-25 16:34:30,389] Trial 16 finished with value: -162.4036865234375 and parameters: {'batch_size': 10388, 'gamma': 0.9261107816921224, 'learning_rate': 1.1150926254907182e-05, 'clip_range': 0.26001343872520577, 'gae_lambda': 0.8399894404261151}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 87085, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_18
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 806       |
|    ep_rew_mean     | -131.7548 |
| time/              |           |
|    fps             | 525       |
|    iterations      | 1         |
|    time_elapsed    | 46        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 837           |
|    ep_rew_mean          | -161.41689    |
| time/                   |               |
|    fps                  | 508           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.1398515e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000787      |
|    learning_rate        | 1.67e-05      |
|    loss                 | 8.83          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.98e-05     |
|    value_loss           | 17.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 820          |
|    ep_rew_mean          | -166.82782   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.833296e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.149        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000786    |
|    learning_rate        | 1.67e-05     |
|    loss                 | 12.7         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.49e-05    |
|    value_loss           | 25.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -172.31203    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.2658124e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00151       |
|    learning_rate        | 1.67e-05      |
|    loss                 | 8.51          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.25e-05     |
|    value_loss           | 17.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -171.56548    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.6350277e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00192      |
|    learning_rate        | 1.67e-05      |
|    loss                 | 9.09          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.11e-05     |
|    value_loss           | 18.2          |
-------------------------------------------
mean_reward
-252.12236
[I 2022-04-25 16:39:00,589] Trial 17 finished with value: -252.1223602294922 and parameters: {'batch_size': 87085, 'gamma': 0.9171989527144467, 'learning_rate': 1.6702407183923095e-05, 'clip_range': 0.14881451250482203, 'gae_lambda': 0.9130072905381323}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 29743, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_19
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 844        |
|    ep_rew_mean     | -139.48596 |
| time/              |            |
|    fps             | 528        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 860          |
|    ep_rew_mean          | -151.38116   |
| time/                   |              |
|    fps                  | 519          |
|    iterations           | 2            |
|    time_elapsed         | 94           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.972617e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.131        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00232      |
|    learning_rate        | 3.06e-05     |
|    loss                 | 19.3         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.86e-05    |
|    value_loss           | 38.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 857          |
|    ep_rew_mean          | -155.81773   |
| time/                   |              |
|    fps                  | 509          |
|    iterations           | 3            |
|    time_elapsed         | 144          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.564913e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.131        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00243      |
|    learning_rate        | 3.06e-05     |
|    loss                 | 17.3         |
|    n_updates            | 20           |
|    policy_gradient_loss | -2.11e-05    |
|    value_loss           | 34.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 846          |
|    ep_rew_mean          | -157.83292   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 1.545365e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.131        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00212      |
|    learning_rate        | 3.06e-05     |
|    loss                 | 20.2         |
|    n_updates            | 30           |
|    policy_gradient_loss | -2.01e-05    |
|    value_loss           | 40.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 827          |
|    ep_rew_mean          | -151.6447    |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 1.619604e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.131        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0052       |
|    learning_rate        | 3.06e-05     |
|    loss                 | 21.6         |
|    n_updates            | 40           |
|    policy_gradient_loss | -2.19e-05    |
|    value_loss           | 43.4         |
------------------------------------------
mean_reward
-137.03804
[I 2022-04-25 16:43:33,714] Trial 18 finished with value: -137.0380401611328 and parameters: {'batch_size': 29743, 'gamma': 0.9521043866270972, 'learning_rate': 3.055197541432423e-05, 'clip_range': 0.13144296836267305, 'gae_lambda': 0.9598333447836066}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 64592, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_20
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 780        |
|    ep_rew_mean     | -149.46475 |
| time/              |            |
|    fps             | 526        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 813          |
|    ep_rew_mean          | -142.19785   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 7.600708e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.292        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00235      |
|    learning_rate        | 1.32e-05     |
|    loss                 | 7.05         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.42e-05    |
|    value_loss           | 14.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 805           |
|    ep_rew_mean          | -143.02959    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.3912423e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.292         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00408       |
|    learning_rate        | 1.32e-05      |
|    loss                 | 8.58          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.17e-05     |
|    value_loss           | 17.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 806           |
|    ep_rew_mean          | -151.87114    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.6583107e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.292         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00231       |
|    learning_rate        | 1.32e-05      |
|    loss                 | 11.1          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.02e-05     |
|    value_loss           | 22.1          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 827         |
|    ep_rew_mean          | -156.88782  |
| time/                   |             |
|    fps                  | 494         |
|    iterations           | 5           |
|    time_elapsed         | 248         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 4.84118e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.292       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.00154     |
|    learning_rate        | 1.32e-05    |
|    loss                 | 7.59        |
|    n_updates            | 40          |
|    policy_gradient_loss | -9.42e-06   |
|    value_loss           | 15.2        |
-----------------------------------------
mean_reward
-175.70552
[I 2022-04-25 16:48:01,406] Trial 19 finished with value: -175.7055206298828 and parameters: {'batch_size': 64592, 'gamma': 0.9921034050735829, 'learning_rate': 1.3166668454020805e-05, 'clip_range': 0.29221443998383445, 'gae_lambda': 0.8350809517593166}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 46571, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_21
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 932        |
|    ep_rew_mean     | -157.49754 |
| time/              |            |
|    fps             | 556        |
|    iterations      | 1          |
|    time_elapsed    | 44         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 851          |
|    ep_rew_mean          | -158.47388   |
| time/                   |              |
|    fps                  | 521          |
|    iterations           | 2            |
|    time_elapsed         | 94           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.510836e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.195        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00645     |
|    learning_rate        | 1.99e-05     |
|    loss                 | 9.31         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.02e-05    |
|    value_loss           | 18.7         |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 839            |
|    ep_rew_mean          | -156.85985     |
| time/                   |                |
|    fps                  | 503            |
|    iterations           | 3              |
|    time_elapsed         | 146            |
|    total_timesteps      | 73728          |
| train/                  |                |
|    approx_kl            | 1.13124166e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.195          |
|    entropy_loss         | -3.89          |
|    explained_variance   | -0.0059        |
|    learning_rate        | 1.99e-05       |
|    loss                 | 9.56           |
|    n_updates            | 20             |
|    policy_gradient_loss | -1.52e-05      |
|    value_loss           | 19.2           |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 858           |
|    ep_rew_mean          | -155.79553    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 4             |
|    time_elapsed         | 194           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.2095067e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.195         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00341      |
|    learning_rate        | 1.99e-05      |
|    loss                 | 9.43          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.55e-05     |
|    value_loss           | 18.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 833           |
|    ep_rew_mean          | -157.95792    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4293619e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.195         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00318      |
|    learning_rate        | 1.99e-05      |
|    loss                 | 10.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.82e-05     |
|    value_loss           | 20.3          |
-------------------------------------------
mean_reward
-179.91956
[I 2022-04-25 16:52:33,801] Trial 20 finished with value: -179.9195556640625 and parameters: {'batch_size': 46571, 'gamma': 0.9702778112647089, 'learning_rate': 1.988014452247951e-05, 'clip_range': 0.19517701493387607, 'gae_lambda': 0.8744619823902346}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 27943, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_22
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 749        |
|    ep_rew_mean     | -128.70766 |
| time/              |            |
|    fps             | 526        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 814           |
|    ep_rew_mean          | -146.77512    |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.0408896e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000326      |
|    learning_rate        | 3.33e-05      |
|    loss                 | 20.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.75e-05     |
|    value_loss           | 41.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 811           |
|    ep_rew_mean          | -155.32468    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.1842911e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000884      |
|    learning_rate        | 3.33e-05      |
|    loss                 | 19.4          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.51e-05     |
|    value_loss           | 39            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 840           |
|    ep_rew_mean          | -155.60161    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.9707174e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00109       |
|    learning_rate        | 3.33e-05      |
|    loss                 | 19.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.01e-05     |
|    value_loss           | 39.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 823           |
|    ep_rew_mean          | -157.82672    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.1901846e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00173       |
|    learning_rate        | 3.33e-05      |
|    loss                 | 19.8          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.33e-05     |
|    value_loss           | 39.8          |
-------------------------------------------
mean_reward
-187.42924
[I 2022-04-25 16:57:01,850] Trial 21 finished with value: -187.4292449951172 and parameters: {'batch_size': 27943, 'gamma': 0.9509521963953127, 'learning_rate': 3.3316611978443714e-05, 'clip_range': 0.12692780529500802, 'gae_lambda': 0.9692369301208283}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 34102, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_23
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 867        |
|    ep_rew_mean     | -145.13664 |
| time/              |            |
|    fps             | 521        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 862           |
|    ep_rew_mean          | -143.62871    |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.8368066e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.143         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00111      |
|    learning_rate        | 3.39e-05      |
|    loss                 | 25.3          |
|    n_updates            | 10            |
|    policy_gradient_loss | -5.24e-05     |
|    value_loss           | 50.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 839           |
|    ep_rew_mean          | -148.6777     |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.6465007e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.143         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00208      |
|    learning_rate        | 3.39e-05      |
|    loss                 | 33.5          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.11e-05     |
|    value_loss           | 67.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 852          |
|    ep_rew_mean          | -150.30547   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 1.609078e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.143        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00191     |
|    learning_rate        | 3.39e-05     |
|    loss                 | 24.3         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.96e-05    |
|    value_loss           | 48.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 832           |
|    ep_rew_mean          | -159.39491    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4749821e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.143         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00107      |
|    learning_rate        | 3.39e-05      |
|    loss                 | 25.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.9e-05      |
|    value_loss           | 51.6          |
-------------------------------------------
mean_reward
-178.47562
[I 2022-04-25 17:01:40,329] Trial 22 finished with value: -178.47561645507812 and parameters: {'batch_size': 34102, 'gamma': 0.9791254507589534, 'learning_rate': 3.393183616502942e-05, 'clip_range': 0.14336931928220922, 'gae_lambda': 0.9481757515693761}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 18956, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 5620
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_24
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 887        |
|    ep_rew_mean     | -153.90553 |
| time/              |            |
|    fps             | 533        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 871           |
|    ep_rew_mean          | -134.15257    |
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 2             |
|    time_elapsed         | 95            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 5.3087945e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00208      |
|    learning_rate        | 2.65e-05      |
|    loss                 | 11.9          |
|    n_updates            | 10            |
|    policy_gradient_loss | -7.18e-05     |
|    value_loss           | 23.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 880           |
|    ep_rew_mean          | -141.72878    |
| time/                   |               |
|    fps                  | 509           |
|    iterations           | 3             |
|    time_elapsed         | 144           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.0260107e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0017       |
|    learning_rate        | 2.65e-05      |
|    loss                 | 12.1          |
|    n_updates            | 20            |
|    policy_gradient_loss | -4.63e-05     |
|    value_loss           | 24.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 870           |
|    ep_rew_mean          | -146.16582    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 3.3667914e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000216      |
|    learning_rate        | 2.65e-05      |
|    loss                 | 15.4          |
|    n_updates            | 30            |
|    policy_gradient_loss | -4e-05        |
|    value_loss           | 26.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 855           |
|    ep_rew_mean          | -154.28403    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.5141414e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00158      |
|    learning_rate        | 2.65e-05      |
|    loss                 | 10.9          |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.63e-05     |
|    value_loss           | 21.3          |
-------------------------------------------
mean_reward
-126.76378
[I 2022-04-25 17:06:07,143] Trial 23 finished with value: -126.76377868652344 and parameters: {'batch_size': 18956, 'gamma': 0.9319429213409712, 'learning_rate': 2.65261636738494e-05, 'clip_range': 0.1185116714442252, 'gae_lambda': 0.931624747198447}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 21124, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 3452
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_25
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 910        |
|    ep_rew_mean     | -139.47548 |
| time/              |            |
|    fps             | 532        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 865           |
|    ep_rew_mean          | -151.10321    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.6403236e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000906      |
|    learning_rate        | 2.15e-05      |
|    loss                 | 11.2          |
|    n_updates            | 10            |
|    policy_gradient_loss | -5.39e-05     |
|    value_loss           | 22.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -157.8729     |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.9521119e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | -6.22e-05     |
|    learning_rate        | 2.15e-05      |
|    loss                 | 11.1          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.78e-05     |
|    value_loss           | 21.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 834           |
|    ep_rew_mean          | -161.68431    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.6398305e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00229       |
|    learning_rate        | 2.15e-05      |
|    loss                 | 10.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.85e-05     |
|    value_loss           | 22.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 816           |
|    ep_rew_mean          | -161.72702    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 5             |
|    time_elapsed         | 250           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.1890457e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00281       |
|    learning_rate        | 2.15e-05      |
|    loss                 | 10.6          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.87e-05     |
|    value_loss           | 22.2          |
-------------------------------------------
mean_reward
-174.71127
[I 2022-04-25 17:10:39,269] Trial 24 finished with value: -174.71127319335938 and parameters: {'batch_size': 21124, 'gamma': 0.9302219911554283, 'learning_rate': 2.1499221850811307e-05, 'clip_range': 0.10007962716391705, 'gae_lambda': 0.9291489749832212}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 11479, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 1618
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_26
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 827       |
|    ep_rew_mean     | -140.8807 |
| time/              |           |
|    fps             | 518       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 840           |
|    ep_rew_mean          | -138.18765    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.3816109e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00329      |
|    learning_rate        | 1.33e-05      |
|    loss                 | 8.32          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.81e-05     |
|    value_loss           | 16.3          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 830         |
|    ep_rew_mean          | -146.1947   |
| time/                   |             |
|    fps                  | 493         |
|    iterations           | 3           |
|    time_elapsed         | 149         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 2.01899e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.156       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.00196    |
|    learning_rate        | 1.33e-05    |
|    loss                 | 7.55        |
|    n_updates            | 20          |
|    policy_gradient_loss | -3.15e-05   |
|    value_loss           | 16.8        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 821           |
|    ep_rew_mean          | -154.13824    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.6326078e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000595     |
|    learning_rate        | 1.33e-05      |
|    loss                 | 7.13          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.73e-05     |
|    value_loss           | 14.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -153.30788    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.2746696e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00131      |
|    learning_rate        | 1.33e-05      |
|    loss                 | 8.54          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.6e-05      |
|    value_loss           | 17.4          |
-------------------------------------------
mean_reward
-207.33696
[I 2022-04-25 17:15:18,910] Trial 25 finished with value: -207.3369598388672 and parameters: {'batch_size': 11479, 'gamma': 0.9168596467899337, 'learning_rate': 1.3345973091787853e-05, 'clip_range': 0.15621219744286788, 'gae_lambda': 0.8977743821823795}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 50363, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_27
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 838       |
|    ep_rew_mean     | -173.9434 |
| time/              |           |
|    fps             | 532       |
|    iterations      | 1         |
|    time_elapsed    | 46        |
|    total_timesteps | 24576     |
----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 831          |
|    ep_rew_mean          | -172.33725   |
| time/                   |              |
|    fps                  | 504          |
|    iterations           | 2            |
|    time_elapsed         | 97           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.937059e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.203        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00157     |
|    learning_rate        | 1.75e-05     |
|    loss                 | 12.4         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.72e-05    |
|    value_loss           | 24.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 832          |
|    ep_rew_mean          | -169.06342   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 6.578193e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.203        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000763    |
|    learning_rate        | 1.75e-05     |
|    loss                 | 10.1         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.4e-05     |
|    value_loss           | 20.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 822           |
|    ep_rew_mean          | -162.98479    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.2000865e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.203         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 3.21e-05      |
|    learning_rate        | 1.75e-05      |
|    loss                 | 10.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.33e-05     |
|    value_loss           | 21.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -169.95097    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 8.0918355e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.203         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00135      |
|    learning_rate        | 1.75e-05      |
|    loss                 | 10.6          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.5e-05      |
|    value_loss           | 21.2          |
-------------------------------------------
mean_reward
-215.80664
[I 2022-04-25 17:19:54,984] Trial 26 finished with value: -215.806640625 and parameters: {'batch_size': 50363, 'gamma': 0.9363005042899681, 'learning_rate': 1.7541685978826064e-05, 'clip_range': 0.20277327535936449, 'gae_lambda': 0.9131919923806847}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 22715, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 1861
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_28
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 896        |
|    ep_rew_mean     | -168.79639 |
| time/              |            |
|    fps             | 546        |
|    iterations      | 1          |
|    time_elapsed    | 44         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 818          |
|    ep_rew_mean          | -159.1454    |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 3.764898e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.182        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0038       |
|    learning_rate        | 2.67e-05     |
|    loss                 | 23.8         |
|    n_updates            | 10           |
|    policy_gradient_loss | -5.53e-05    |
|    value_loss           | 46.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 814          |
|    ep_rew_mean          | -156.45639   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 2.169871e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.182        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00253      |
|    learning_rate        | 2.67e-05     |
|    loss                 | 23.5         |
|    n_updates            | 20           |
|    policy_gradient_loss | -2.83e-05    |
|    value_loss           | 46.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 806           |
|    ep_rew_mean          | -154.35974    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.4967885e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.182         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.0018        |
|    learning_rate        | 2.67e-05      |
|    loss                 | 17.6          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.25e-05     |
|    value_loss           | 35.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -147.6959     |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.9693732e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.182         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00306       |
|    learning_rate        | 2.67e-05      |
|    loss                 | 17.6          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.8e-05      |
|    value_loss           | 36.5          |
-------------------------------------------
mean_reward
-179.41573
[I 2022-04-25 17:24:22,536] Trial 27 finished with value: -179.4157257080078 and parameters: {'batch_size': 22715, 'gamma': 0.9239963033125091, 'learning_rate': 2.6705063661919743e-05, 'clip_range': 0.18206142764222502, 'gae_lambda': 0.989710160203175}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 36758, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_29
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 793       |
|    ep_rew_mean     | -121.0746 |
| time/              |           |
|    fps             | 511       |
|    iterations      | 1         |
|    time_elapsed    | 48        |
|    total_timesteps | 24576     |
----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 831          |
|    ep_rew_mean          | -140.93916   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 7.021299e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.233        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0083      |
|    learning_rate        | 1.2e-05      |
|    loss                 | 10.8         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.31e-05    |
|    value_loss           | 21.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 834          |
|    ep_rew_mean          | -151.9839    |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 4.452401e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.233        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00636     |
|    learning_rate        | 1.2e-05      |
|    loss                 | 8.89         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.03e-05    |
|    value_loss           | 17.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 863          |
|    ep_rew_mean          | -153.89723   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.401753e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.233        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00578     |
|    learning_rate        | 1.2e-05      |
|    loss                 | 8.99         |
|    n_updates            | 30           |
|    policy_gradient_loss | -9.05e-06    |
|    value_loss           | 18           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 856           |
|    ep_rew_mean          | -157.0705     |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.8407357e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.233         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00535      |
|    learning_rate        | 1.2e-05       |
|    loss                 | 12.4          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.03e-05     |
|    value_loss           | 24.9          |
-------------------------------------------
mean_reward
-198.60812
[I 2022-04-25 17:28:50,143] Trial 28 finished with value: -198.60812377929688 and parameters: {'batch_size': 36758, 'gamma': 0.9098878956858429, 'learning_rate': 1.1987141259656056e-05, 'clip_range': 0.23279748008458195, 'gae_lambda': 0.9344699644935296}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 92310, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_30
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 815       |
|    ep_rew_mean     | -140.8864 |
| time/              |           |
|    fps             | 509       |
|    iterations      | 1         |
|    time_elapsed    | 48        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 836           |
|    ep_rew_mean          | -141.13676    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.1843395e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.121         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000746     |
|    learning_rate        | 2.44e-05      |
|    loss                 | 21.5          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.12e-05     |
|    value_loss           | 43            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 834           |
|    ep_rew_mean          | -155.25589    |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.5813082e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.121         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -8.95e-05     |
|    learning_rate        | 2.44e-05      |
|    loss                 | 21.4          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.11e-05     |
|    value_loss           | 43            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 831           |
|    ep_rew_mean          | -154.85431    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.1063579e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.121         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00181       |
|    learning_rate        | 2.44e-05      |
|    loss                 | 19.6          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.44e-05     |
|    value_loss           | 39.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 829          |
|    ep_rew_mean          | -147.18178   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 1.071118e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.121        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0016       |
|    learning_rate        | 2.44e-05     |
|    loss                 | 24.4         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.81e-05    |
|    value_loss           | 48.9         |
------------------------------------------
mean_reward
-197.8589
[I 2022-04-25 17:33:24,587] Trial 29 finished with value: -197.85890197753906 and parameters: {'batch_size': 92310, 'gamma': 0.9462616570896472, 'learning_rate': 2.4413348725595995e-05, 'clip_range': 0.12107597018275286, 'gae_lambda': 0.9725514886910537}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 67076, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_31
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | -134.894 |
| time/              |          |
|    fps             | 522      |
|    iterations      | 1        |
|    time_elapsed    | 47       |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 831           |
|    ep_rew_mean          | -152.50352    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.0308896e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.166         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00764      |
|    learning_rate        | 1.81e-05      |
|    loss                 | 10.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.54e-05     |
|    value_loss           | 20.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 829          |
|    ep_rew_mean          | -154.83942   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.381135e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.166        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00499     |
|    learning_rate        | 1.81e-05     |
|    loss                 | 11.3         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.32e-05    |
|    value_loss           | 22.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 832           |
|    ep_rew_mean          | -150.84209    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 8.5473104e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.166         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00564      |
|    learning_rate        | 1.81e-05      |
|    loss                 | 9.77          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.5e-05      |
|    value_loss           | 19.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 809           |
|    ep_rew_mean          | -155.8661     |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0196285e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.166         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00546      |
|    learning_rate        | 1.81e-05      |
|    loss                 | 9.6           |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.69e-05     |
|    value_loss           | 19.2          |
-------------------------------------------
mean_reward
-183.19499
[I 2022-04-25 17:37:55,409] Trial 30 finished with value: -183.1949920654297 and parameters: {'batch_size': 67076, 'gamma': 0.9342598118671512, 'learning_rate': 1.807323230969238e-05, 'clip_range': 0.16599682053226772, 'gae_lambda': 0.9084888314564726}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 27066, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_32
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 827        |
|    ep_rew_mean     | -136.67589 |
| time/              |            |
|    fps             | 527        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 854           |
|    ep_rew_mean          | -138.41695    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.6362736e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.129         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000418     |
|    learning_rate        | 3.02e-05      |
|    loss                 | 19.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.87e-05     |
|    value_loss           | 39.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 860           |
|    ep_rew_mean          | -147.31395    |
| time/                   |               |
|    fps                  | 509           |
|    iterations           | 3             |
|    time_elapsed         | 144           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.6148503e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.129         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00103       |
|    learning_rate        | 3.02e-05      |
|    loss                 | 19.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.25e-05     |
|    value_loss           | 38.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -155.57433    |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 4             |
|    time_elapsed         | 193           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.3013778e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.129         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00111       |
|    learning_rate        | 3.02e-05      |
|    loss                 | 18.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.78e-05     |
|    value_loss           | 37.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 856           |
|    ep_rew_mean          | -158.84552    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 5             |
|    time_elapsed         | 244           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 9.9527824e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.129         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000597      |
|    learning_rate        | 3.02e-05      |
|    loss                 | 17.4          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.53e-05     |
|    value_loss           | 34.9          |
-------------------------------------------
mean_reward
-213.38142
[I 2022-04-25 17:42:14,052] Trial 31 finished with value: -213.3814239501953 and parameters: {'batch_size': 27066, 'gamma': 0.9504322444920232, 'learning_rate': 3.02462432623059e-05, 'clip_range': 0.12947078813576907, 'gae_lambda': 0.9553595051090736}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 17499, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 7077
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_33
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 741       |
|    ep_rew_mean     | -168.0632 |
| time/              |           |
|    fps             | 510       |
|    iterations      | 1         |
|    time_elapsed    | 48        |
|    total_timesteps | 24576     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 812         |
|    ep_rew_mean          | -166.36847  |
| time/                   |             |
|    fps                  | 505         |
|    iterations           | 2           |
|    time_elapsed         | 97          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 9.78469e-07 |
|    clip_fraction        | 0           |
|    clip_range           | 0.144       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.00219     |
|    learning_rate        | 3.82e-05    |
|    loss                 | 27.9        |
|    n_updates            | 10          |
|    policy_gradient_loss | -9.27e-05   |
|    value_loss           | 56.3        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -158.47458    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 6.2113634e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.144         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00353       |
|    learning_rate        | 3.82e-05      |
|    loss                 | 23            |
|    n_updates            | 20            |
|    policy_gradient_loss | -5.17e-05     |
|    value_loss           | 47.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 835           |
|    ep_rew_mean          | -159.90192    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.7555405e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.144         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00481       |
|    learning_rate        | 3.82e-05      |
|    loss                 | 28.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -5.25e-05     |
|    value_loss           | 53.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 831          |
|    ep_rew_mean          | -152.49274   |
| time/                   |              |
|    fps                  | 491          |
|    iterations           | 5            |
|    time_elapsed         | 249          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.878074e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.144        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00184      |
|    learning_rate        | 3.82e-05     |
|    loss                 | 20.8         |
|    n_updates            | 40           |
|    policy_gradient_loss | -4.67e-05    |
|    value_loss           | 42.2         |
------------------------------------------
mean_reward
-183.14107
[I 2022-04-25 17:46:55,654] Trial 32 finished with value: -183.1410675048828 and parameters: {'batch_size': 17499, 'gamma': 0.9638841711574404, 'learning_rate': 3.8171534447316526e-05, 'clip_range': 0.14410119719084152, 'gae_lambda': 0.9637876463106904}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 41003, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_34
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 790        |
|    ep_rew_mean     | -166.39784 |
| time/              |            |
|    fps             | 518        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 795           |
|    ep_rew_mean          | -157.42923    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.3857304e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.124         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000753     |
|    learning_rate        | 2.68e-05      |
|    loss                 | 28.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.58e-05     |
|    value_loss           | 57.7          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 822            |
|    ep_rew_mean          | -155.49208     |
| time/                   |                |
|    fps                  | 498            |
|    iterations           | 3              |
|    time_elapsed         | 147            |
|    total_timesteps      | 73728          |
| train/                  |                |
|    approx_kl            | 1.03046965e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.124          |
|    entropy_loss         | -3.89          |
|    explained_variance   | -0.00293       |
|    learning_rate        | 2.68e-05       |
|    loss                 | 27.8           |
|    n_updates            | 20             |
|    policy_gradient_loss | -1.9e-05       |
|    value_loss           | 55.7           |
--------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 834            |
|    ep_rew_mean          | -161.0387      |
| time/                   |                |
|    fps                  | 492            |
|    iterations           | 4              |
|    time_elapsed         | 199            |
|    total_timesteps      | 98304          |
| train/                  |                |
|    approx_kl            | 1.03059094e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.124          |
|    entropy_loss         | -3.89          |
|    explained_variance   | -0.00129       |
|    learning_rate        | 2.68e-05       |
|    loss                 | 30.5           |
|    n_updates            | 30             |
|    policy_gradient_loss | -1.69e-05      |
|    value_loss           | 61.2           |
--------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 840          |
|    ep_rew_mean          | -165.66383   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 5            |
|    time_elapsed         | 249          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.439182e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.124        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000989     |
|    learning_rate        | 2.68e-05     |
|    loss                 | 29.5         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.29e-05    |
|    value_loss           | 59.2         |
------------------------------------------
mean_reward
-218.59428
[I 2022-04-25 17:51:31,982] Trial 33 finished with value: -218.5942840576172 and parameters: {'batch_size': 41003, 'gamma': 0.955381283948479, 'learning_rate': 2.6780567083388827e-05, 'clip_range': 0.1235638360565403, 'gae_lambda': 0.9769687749593512}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 27559, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_35
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 849        |
|    ep_rew_mean     | -137.57661 |
| time/              |            |
|    fps             | 529        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 862           |
|    ep_rew_mean          | -136.05704    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.9721483e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.107         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000207      |
|    learning_rate        | 2.41e-05      |
|    loss                 | 14.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.92e-05     |
|    value_loss           | 28.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 864           |
|    ep_rew_mean          | -138.30888    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.1139249e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.107         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -1.62e-05     |
|    learning_rate        | 2.41e-05      |
|    loss                 | 19.7          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.91e-05     |
|    value_loss           | 39.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 869          |
|    ep_rew_mean          | -139.91649   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.283637e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.107        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000615     |
|    learning_rate        | 2.41e-05     |
|    loss                 | 19.3         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.52e-05    |
|    value_loss           | 38.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 848           |
|    ep_rew_mean          | -146.78232    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 5             |
|    time_elapsed         | 244           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0685471e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.107         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00214       |
|    learning_rate        | 2.41e-05      |
|    loss                 | 16.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.61e-05     |
|    value_loss           | 32.3          |
-------------------------------------------
mean_reward
-189.0375
[I 2022-04-25 17:56:02,870] Trial 34 finished with value: -189.03750610351562 and parameters: {'batch_size': 27559, 'gamma': 0.9628908507123971, 'learning_rate': 2.4050644074483148e-05, 'clip_range': 0.10708705824070619, 'gae_lambda': 0.939953578253582}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 31936, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_36
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 822        |
|    ep_rew_mean     | -153.51369 |
| time/              |            |
|    fps             | 523        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 829           |
|    ep_rew_mean          | -156.7345     |
| time/                   |               |
|    fps                  | 509           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.8531864e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.18          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00142       |
|    learning_rate        | 2.11e-05      |
|    loss                 | 16.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.59e-05     |
|    value_loss           | 33.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 834           |
|    ep_rew_mean          | -151.47385    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.1497468e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.18          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000881      |
|    learning_rate        | 2.11e-05      |
|    loss                 | 15.4          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.55e-05     |
|    value_loss           | 30.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 821          |
|    ep_rew_mean          | -143.09583   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.790286e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.18         |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00333      |
|    learning_rate        | 2.11e-05     |
|    loss                 | 16.9         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.64e-05    |
|    value_loss           | 33.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 826          |
|    ep_rew_mean          | -147.9766    |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 9.200934e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.18         |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00177      |
|    learning_rate        | 2.11e-05     |
|    loss                 | 18.2         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.25e-05    |
|    value_loss           | 36.5         |
------------------------------------------
mean_reward
-193.78323
[I 2022-04-25 18:00:36,631] Trial 35 finished with value: -193.78323364257812 and parameters: {'batch_size': 31936, 'gamma': 0.9406401002930511, 'learning_rate': 2.108074179465434e-05, 'clip_range': 0.18037688647021954, 'gae_lambda': 0.9572164276746943}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 22712, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 1864
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_37
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 813        |
|    ep_rew_mean     | -175.54515 |
| time/              |            |
|    fps             | 530        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 857          |
|    ep_rew_mean          | -168.08832   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 1.170355e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.114        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000918    |
|    learning_rate        | 1.48e-05     |
|    loss                 | 8.77         |
|    n_updates            | 10           |
|    policy_gradient_loss | -3.22e-05    |
|    value_loss           | 20.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 843           |
|    ep_rew_mean          | -163.28412    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 9.2807674e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.114         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000218      |
|    learning_rate        | 1.48e-05      |
|    loss                 | 10.5          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.97e-05     |
|    value_loss           | 21.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 847          |
|    ep_rew_mean          | -166.46385   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.842903e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.114        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0013      |
|    learning_rate        | 1.48e-05     |
|    loss                 | 11.8         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.57e-05    |
|    value_loss           | 23.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 864          |
|    ep_rew_mean          | -157.51385   |
| time/                   |              |
|    fps                  | 504          |
|    iterations           | 5            |
|    time_elapsed         | 243          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 6.424017e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.114        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000289     |
|    learning_rate        | 1.48e-05     |
|    loss                 | 12.7         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.34e-05    |
|    value_loss           | 23.5         |
------------------------------------------
mean_reward
-185.80768
[I 2022-04-25 18:05:00,556] Trial 36 finished with value: -185.80767822265625 and parameters: {'batch_size': 22712, 'gamma': 0.984817922042314, 'learning_rate': 1.4792393319438913e-05, 'clip_range': 0.114042671286658, 'gae_lambda': 0.8850936650790739}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 101862, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_38
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 771        |
|    ep_rew_mean     | -159.41716 |
| time/              |            |
|    fps             | 504        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 774          |
|    ep_rew_mean          | -149.42043   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.676728e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.159        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00142     |
|    learning_rate        | 2.91e-05     |
|    loss                 | 13.3         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.62e-05    |
|    value_loss           | 26.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 796          |
|    ep_rew_mean          | -149.39107   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.847681e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.159        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000294    |
|    learning_rate        | 2.91e-05     |
|    loss                 | 15           |
|    n_updates            | 20           |
|    policy_gradient_loss | -2.65e-05    |
|    value_loss           | 30.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 810           |
|    ep_rew_mean          | -148.41956    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.4482552e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.159         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000465      |
|    learning_rate        | 2.91e-05      |
|    loss                 | 14.4          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.78e-05     |
|    value_loss           | 29            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 840          |
|    ep_rew_mean          | -146.47824   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 9.625607e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.159        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0017       |
|    learning_rate        | 2.91e-05     |
|    loss                 | 15.6         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.49e-05    |
|    value_loss           | 31.3         |
------------------------------------------
mean_reward
-184.4119
[I 2022-04-25 18:09:26,805] Trial 37 finished with value: -184.41189575195312 and parameters: {'batch_size': 101862, 'gamma': 0.911516667399844, 'learning_rate': 2.9069299538185358e-05, 'clip_range': 0.15896043667014398, 'gae_lambda': 0.9780750455682333}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 47197, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_39
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 782       |
|    ep_rew_mean     | -169.0732 |
| time/              |           |
|    fps             | 516       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 782           |
|    ep_rew_mean          | -164.93077    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.1932329e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.142         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000916     |
|    learning_rate        | 2.01e-05      |
|    loss                 | 19            |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.04e-05     |
|    value_loss           | 38.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 797          |
|    ep_rew_mean          | -157.3806    |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 3            |
|    time_elapsed         | 149          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.561903e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.142        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000294    |
|    learning_rate        | 2.01e-05     |
|    loss                 | 22.1         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.41e-05    |
|    value_loss           | 44.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 809           |
|    ep_rew_mean          | -157.12415    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 8.0343554e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.142         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00141       |
|    learning_rate        | 2.01e-05      |
|    loss                 | 18.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.43e-05     |
|    value_loss           | 37.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 825          |
|    ep_rew_mean          | -162.74463   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 8.302353e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.142        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000795     |
|    learning_rate        | 2.01e-05     |
|    loss                 | 20.9         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.44e-05    |
|    value_loss           | 41.9         |
------------------------------------------
mean_reward
-275.80502
[I 2022-04-25 18:14:05,745] Trial 38 finished with value: -275.8050231933594 and parameters: {'batch_size': 47197, 'gamma': 0.9750405217259579, 'learning_rate': 2.0082207143255594e-05, 'clip_range': 0.14208183863707913, 'gae_lambda': 0.9286734704271354}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 20018, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 4558
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_40
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 772        |
|    ep_rew_mean     | -168.29741 |
| time/              |            |
|    fps             | 512        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 805           |
|    ep_rew_mean          | -166.10732    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.2889125e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.34          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00151      |
|    learning_rate        | 3.64e-05      |
|    loss                 | 13.1          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000103     |
|    value_loss           | 25.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 811           |
|    ep_rew_mean          | -166.42592    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 7.1138174e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.34          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00194      |
|    learning_rate        | 3.64e-05      |
|    loss                 | 11            |
|    n_updates            | 20            |
|    policy_gradient_loss | -5.11e-05     |
|    value_loss           | 22.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 844          |
|    ep_rew_mean          | -165.13872   |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.448244e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.34         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00224     |
|    learning_rate        | 3.64e-05     |
|    loss                 | 11.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -5.84e-05    |
|    value_loss           | 23.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 843           |
|    ep_rew_mean          | -161.27707    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.1020614e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.34          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 1.25e-05      |
|    learning_rate        | 3.64e-05      |
|    loss                 | 11.3          |
|    n_updates            | 40            |
|    policy_gradient_loss | -6.84e-05     |
|    value_loss           | 23            |
-------------------------------------------
mean_reward
-199.30368
[I 2022-04-25 18:18:47,289] Trial 39 finished with value: -199.30368041992188 and parameters: {'batch_size': 20018, 'gamma': 0.9225881634872282, 'learning_rate': 3.6399919000859734e-05, 'clip_range': 0.3403824882276313, 'gae_lambda': 0.952801672503792}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 37133, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_41
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 833        |
|    ep_rew_mean     | -146.70596 |
| time/              |            |
|    fps             | 529        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -145.63008    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.8359017e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00336      |
|    learning_rate        | 2.42e-05      |
|    loss                 | 8.78          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.67e-05     |
|    value_loss           | 17.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 836           |
|    ep_rew_mean          | -142.0753     |
| time/                   |               |
|    fps                  | 505           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.2453044e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00461      |
|    learning_rate        | 2.42e-05      |
|    loss                 | 9.25          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.05e-05     |
|    value_loss           | 18.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -140.44138   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 1.073034e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00241     |
|    learning_rate        | 2.42e-05     |
|    loss                 | 10.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.79e-05    |
|    value_loss           | 21.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 838           |
|    ep_rew_mean          | -141.25082    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0198225e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000716     |
|    learning_rate        | 2.42e-05      |
|    loss                 | 8.77          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.8e-05      |
|    value_loss           | 17.6          |
-------------------------------------------
mean_reward
-178.41164
[I 2022-04-25 18:23:17,165] Trial 40 finished with value: -178.41163635253906 and parameters: {'batch_size': 37133, 'gamma': 0.9306211950577579, 'learning_rate': 2.4227403994781615e-05, 'clip_range': 0.100315924466849, 'gae_lambda': 0.9025138757142218}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 81955, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_42
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 717        |
|    ep_rew_mean     | -130.86797 |
| time/              |            |
|    fps             | 516        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 755           |
|    ep_rew_mean          | -150.48401    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.2747022e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.195         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00426      |
|    learning_rate        | 6.94e-05      |
|    loss                 | 9.39          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000136     |
|    value_loss           | 18.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 785          |
|    ep_rew_mean          | -147.8934    |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 3            |
|    time_elapsed         | 150          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.322888e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.195        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00218     |
|    learning_rate        | 6.94e-05     |
|    loss                 | 10.1         |
|    n_updates            | 20           |
|    policy_gradient_loss | -5.87e-05    |
|    value_loss           | 20.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -159.48146    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.1746791e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.195         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00345       |
|    learning_rate        | 6.94e-05      |
|    loss                 | 8.31          |
|    n_updates            | 30            |
|    policy_gradient_loss | -5.79e-05     |
|    value_loss           | 16.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 835           |
|    ep_rew_mean          | -160.03201    |
| time/                   |               |
|    fps                  | 490           |
|    iterations           | 5             |
|    time_elapsed         | 250           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.2704429e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.195         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00333       |
|    learning_rate        | 6.94e-05      |
|    loss                 | 9.78          |
|    n_updates            | 40            |
|    policy_gradient_loss | -5.76e-05     |
|    value_loss           | 19.7          |
-------------------------------------------
mean_reward
-220.80737
[I 2022-04-25 18:27:41,082] Trial 41 finished with value: -220.807373046875 and parameters: {'batch_size': 81955, 'gamma': 0.9361404678694318, 'learning_rate': 6.944554009311247e-05, 'clip_range': 0.19476478264649846, 'gae_lambda': 0.8864105780784051}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 79022, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_43
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 820        |
|    ep_rew_mean     | -169.14145 |
| time/              |            |
|    fps             | 517        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 854           |
|    ep_rew_mean          | -165.9388     |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.7969772e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000378     |
|    learning_rate        | 6.42e-05      |
|    loss                 | 11.5          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000116     |
|    value_loss           | 23.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 837           |
|    ep_rew_mean          | -169.80139    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.0818743e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00059       |
|    learning_rate        | 6.42e-05      |
|    loss                 | 14.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -5.63e-05     |
|    value_loss           | 28.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 846          |
|    ep_rew_mean          | -165.681     |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.839003e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.119        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00268      |
|    learning_rate        | 6.42e-05     |
|    loss                 | 10           |
|    n_updates            | 30           |
|    policy_gradient_loss | -4.91e-05    |
|    value_loss           | 20.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 841           |
|    ep_rew_mean          | -163.01907    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0661461e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.119         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00377       |
|    learning_rate        | 6.42e-05      |
|    loss                 | 11.4          |
|    n_updates            | 40            |
|    policy_gradient_loss | -4.66e-05     |
|    value_loss           | 23            |
-------------------------------------------
mean_reward
-251.73799
[I 2022-04-25 18:32:18,369] Trial 42 finished with value: -251.7379913330078 and parameters: {'batch_size': 79022, 'gamma': 0.9458905054424838, 'learning_rate': 6.421287320428309e-05, 'clip_range': 0.11937873348267417, 'gae_lambda': 0.919956787980219}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 69394, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_44
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 822       |
|    ep_rew_mean     | -174.9138 |
| time/              |           |
|    fps             | 533       |
|    iterations      | 1         |
|    time_elapsed    | 46        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -150.65315    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 5.2839704e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.214         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000497     |
|    learning_rate        | 3.96e-05      |
|    loss                 | 8.19          |
|    n_updates            | 10            |
|    policy_gradient_loss | -6.85e-05     |
|    value_loss           | 16.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -152.39915    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.2409133e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.214         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.0017        |
|    learning_rate        | 3.96e-05      |
|    loss                 | 9.05          |
|    n_updates            | 20            |
|    policy_gradient_loss | -4.17e-05     |
|    value_loss           | 18.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 790          |
|    ep_rew_mean          | -148.26302   |
| time/                   |              |
|    fps                  | 490          |
|    iterations           | 4            |
|    time_elapsed         | 200          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.366416e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.214        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00261      |
|    learning_rate        | 3.96e-05     |
|    loss                 | 9.05         |
|    n_updates            | 30           |
|    policy_gradient_loss | -2.89e-05    |
|    value_loss           | 18.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 775           |
|    ep_rew_mean          | -157.1331     |
| time/                   |               |
|    fps                  | 487           |
|    iterations           | 5             |
|    time_elapsed         | 252           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.7370697e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.214         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000642      |
|    learning_rate        | 3.96e-05      |
|    loss                 | 9.5           |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.08e-05     |
|    value_loss           | 19.1          |
-------------------------------------------
mean_reward
-160.18977
[I 2022-04-25 18:36:48,691] Trial 43 finished with value: -160.1897735595703 and parameters: {'batch_size': 69394, 'gamma': 0.9393158361547091, 'learning_rate': 3.9579754124463906e-05, 'clip_range': 0.2141440867772806, 'gae_lambda': 0.889772546636748}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 90856, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_45
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 872        |
|    ep_rew_mean     | -140.06212 |
| time/              |            |
|    fps             | 533        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -139.6928     |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.5107798e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.172         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00286      |
|    learning_rate        | 5.42e-05      |
|    loss                 | 6.5           |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000107     |
|    value_loss           | 13.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 842          |
|    ep_rew_mean          | -147.17537   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.920695e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.172        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00352      |
|    learning_rate        | 5.42e-05     |
|    loss                 | 8.84         |
|    n_updates            | 20           |
|    policy_gradient_loss | -5.5e-05     |
|    value_loss           | 17.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 818          |
|    ep_rew_mean          | -149.74257   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 4            |
|    time_elapsed         | 199          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 6.799868e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.172        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000968     |
|    learning_rate        | 5.42e-05     |
|    loss                 | 8.01         |
|    n_updates            | 30           |
|    policy_gradient_loss | -4.32e-05    |
|    value_loss           | 16.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 824          |
|    ep_rew_mean          | -161.9175    |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 5            |
|    time_elapsed         | 249          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 8.241308e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.172        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00302      |
|    learning_rate        | 5.42e-05     |
|    loss                 | 7.59         |
|    n_updates            | 40           |
|    policy_gradient_loss | -4.73e-05    |
|    value_loss           | 15.3         |
------------------------------------------
mean_reward
-182.39343
[I 2022-04-25 18:41:23,808] Trial 44 finished with value: -182.3934326171875 and parameters: {'batch_size': 90856, 'gamma': 0.9308668141123833, 'learning_rate': 5.418487466277316e-05, 'clip_range': 0.1716215808682014, 'gae_lambda': 0.8662955357336205}. Best is trial 14 with value: -104.88569641113281.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 83764, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_46
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 710        |
|    ep_rew_mean     | -177.30194 |
| time/              |            |
|    fps             | 510        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 751          |
|    ep_rew_mean          | -167.82283   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 2            |
|    time_elapsed         | 99           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.287219e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.133        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00173     |
|    learning_rate        | 4.78e-05     |
|    loss                 | 13.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -7.55e-05    |
|    value_loss           | 26.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 758          |
|    ep_rew_mean          | -163.53094   |
| time/                   |              |
|    fps                  | 487          |
|    iterations           | 3            |
|    time_elapsed         | 151          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.312119e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.133        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000675     |
|    learning_rate        | 4.78e-05     |
|    loss                 | 11.2         |
|    n_updates            | 20           |
|    policy_gradient_loss | -5.27e-05    |
|    value_loss           | 22.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 782          |
|    ep_rew_mean          | -156.7247    |
| time/                   |              |
|    fps                  | 485          |
|    iterations           | 4            |
|    time_elapsed         | 202          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 5.662199e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.133        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00163     |
|    learning_rate        | 4.78e-05     |
|    loss                 | 14.8         |
|    n_updates            | 30           |
|    policy_gradient_loss | -3.1e-05     |
|    value_loss           | 29.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 780           |
|    ep_rew_mean          | -150.12509    |
| time/                   |               |
|    fps                  | 486           |
|    iterations           | 5             |
|    time_elapsed         | 252           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 5.0400075e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.133         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00102      |
|    learning_rate        | 4.78e-05      |
|    loss                 | 12            |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.81e-05     |
|    value_loss           | 24.1          |
-------------------------------------------
mean_reward
-159.17526
[I 2022-04-25 18:46:10,924] Trial 45 finished with value: -159.17526245117188 and parameters: {'batch_size': 83764, 'gamma': 0.9017923809537037, 'learning_rate': 4.7793542397135386e-05, 'clip_range': 0.13347938916829388, 'gae_lambda': 0.9636081263097445}. Best is trial 14 with value: -104.88569641113281.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 14096, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 10480
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_47
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 757        |
|    ep_rew_mean     | -137.32542 |
| time/              |            |
|    fps             | 521        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 809          |
|    ep_rew_mean          | -164.52628   |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.964988e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.156        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000473     |
|    learning_rate        | 1.53e-05     |
|    loss                 | 19.3         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.57e-05    |
|    value_loss           | 37.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 806           |
|    ep_rew_mean          | -153.40642    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.5933816e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00213      |
|    learning_rate        | 1.53e-05      |
|    loss                 | 15.8          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.29e-05     |
|    value_loss           | 32.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -149.36127    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.8578173e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00197      |
|    learning_rate        | 1.53e-05      |
|    loss                 | 15.6          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.72e-05     |
|    value_loss           | 30.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 837          |
|    ep_rew_mean          | -151.74088   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 2.431497e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.156        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -8.59e-05    |
|    learning_rate        | 1.53e-05     |
|    loss                 | 17.6         |
|    n_updates            | 40           |
|    policy_gradient_loss | -3.09e-05    |
|    value_loss           | 36           |
------------------------------------------
mean_reward
-95.40401
[I 2022-04-25 18:50:40,405] Trial 46 finished with value: -95.40400695800781 and parameters: {'batch_size': 14096, 'gamma': 0.9218029918431722, 'learning_rate': 1.5250715813762437e-05, 'clip_range': 0.15641244303838023, 'gae_lambda': 0.9829974773462375}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 15838, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 8738
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_48
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 822        |
|    ep_rew_mean     | -124.43885 |
| time/              |            |
|    fps             | 520        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 817           |
|    ep_rew_mean          | -141.92134    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.4815577e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.155         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000247     |
|    learning_rate        | 1.49e-05      |
|    loss                 | 17.7          |
|    n_updates            | 10            |
|    policy_gradient_loss | -5.18e-05     |
|    value_loss           | 35            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 845           |
|    ep_rew_mean          | -144.23929    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.6669213e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.155         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00238      |
|    learning_rate        | 1.49e-05      |
|    loss                 | 15.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.33e-05     |
|    value_loss           | 30.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 838           |
|    ep_rew_mean          | -150.09723    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.9835383e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.155         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000605      |
|    learning_rate        | 1.49e-05      |
|    loss                 | 14.3          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.76e-05     |
|    value_loss           | 29.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 845           |
|    ep_rew_mean          | -152.26404    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.7152894e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.155         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00032       |
|    learning_rate        | 1.49e-05      |
|    loss                 | 14.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.26e-05     |
|    value_loss           | 28.2          |
-------------------------------------------
mean_reward
-196.30208
[I 2022-04-25 18:55:14,614] Trial 47 finished with value: -196.3020782470703 and parameters: {'batch_size': 15838, 'gamma': 0.9145517157176547, 'learning_rate': 1.493592694659496e-05, 'clip_range': 0.15455556650941565, 'gae_lambda': 0.9836832346305431}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 11873, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 830
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_49
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 774        |
|    ep_rew_mean     | -165.32031 |
| time/              |            |
|    fps             | 504        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 779           |
|    ep_rew_mean          | -145.38358    |
| time/                   |               |
|    fps                  | 486           |
|    iterations           | 2             |
|    time_elapsed         | 100           |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4953373e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.113         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00127      |
|    learning_rate        | 1.08e-05      |
|    loss                 | 16.9          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.25e-05     |
|    value_loss           | 34            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 781           |
|    ep_rew_mean          | -148.26239    |
| time/                   |               |
|    fps                  | 488           |
|    iterations           | 3             |
|    time_elapsed         | 150           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.3494338e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.113         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00224      |
|    learning_rate        | 1.08e-05      |
|    loss                 | 13.3          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.41e-05     |
|    value_loss           | 27.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 796           |
|    ep_rew_mean          | -143.84485    |
| time/                   |               |
|    fps                  | 486           |
|    iterations           | 4             |
|    time_elapsed         | 202           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.2623174e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.113         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000133      |
|    learning_rate        | 1.08e-05      |
|    loss                 | 15.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.08e-05     |
|    value_loss           | 28.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 784          |
|    ep_rew_mean          | -141.1195    |
| time/                   |              |
|    fps                  | 486          |
|    iterations           | 5            |
|    time_elapsed         | 252          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 8.872207e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.113        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000242    |
|    learning_rate        | 1.08e-05     |
|    loss                 | 14.7         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.74e-05    |
|    value_loss           | 29.6         |
------------------------------------------
mean_reward
-192.59846
[I 2022-04-25 18:59:49,606] Trial 48 finished with value: -192.5984649658203 and parameters: {'batch_size': 11873, 'gamma': 0.9193512974498388, 'learning_rate': 1.0823907411846385e-05, 'clip_range': 0.11340840838803454, 'gae_lambda': 0.9672690723430395}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 26466, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_50
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 764       |
|    ep_rew_mean     | -130.6261 |
| time/              |           |
|    fps             | 520       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 788           |
|    ep_rew_mean          | -154.22533    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.8783688e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.182         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000964      |
|    learning_rate        | 1.3e-05       |
|    loss                 | 92.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -1.25e-05     |
|    value_loss           | 185           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 809          |
|    ep_rew_mean          | -152.95552   |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.864828e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.182        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000342     |
|    learning_rate        | 1.3e-05      |
|    loss                 | 100          |
|    n_updates            | 20           |
|    policy_gradient_loss | -5.56e-06    |
|    value_loss           | 200          |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 843            |
|    ep_rew_mean          | -154.71922     |
| time/                   |                |
|    fps                  | 498            |
|    iterations           | 4              |
|    time_elapsed         | 197            |
|    total_timesteps      | 98304          |
| train/                  |                |
|    approx_kl            | 1.43263605e-08 |
|    clip_fraction        | 0              |
|    clip_range           | 0.182          |
|    entropy_loss         | -3.89          |
|    explained_variance   | -0.000175      |
|    learning_rate        | 1.3e-05        |
|    loss                 | 94.1           |
|    n_updates            | 30             |
|    policy_gradient_loss | -4.61e-06      |
|    value_loss           | 188            |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 860           |
|    ep_rew_mean          | -154.22502    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4661055e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.182         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000185      |
|    learning_rate        | 1.3e-05       |
|    loss                 | 124           |
|    n_updates            | 40            |
|    policy_gradient_loss | -4.34e-06     |
|    value_loss           | 247           |
-------------------------------------------
mean_reward
-216.16585
[I 2022-04-25 19:04:24,770] Trial 49 finished with value: -216.1658477783203 and parameters: {'batch_size': 26466, 'gamma': 0.989809853840175, 'learning_rate': 1.3049683019195056e-05, 'clip_range': 0.1819222208948929, 'gae_lambda': 0.9819476714188968}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 60707, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_51
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 857        |
|    ep_rew_mean     | -159.84624 |
| time/              |            |
|    fps             | 523        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 852           |
|    ep_rew_mean          | -161.93077    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.6132739e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.135         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000787     |
|    learning_rate        | 1.81e-05      |
|    loss                 | 11.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.31e-05     |
|    value_loss           | 22.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 842          |
|    ep_rew_mean          | -159.62184   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.910421e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.135        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 4.05e-05     |
|    learning_rate        | 1.81e-05     |
|    loss                 | 12.2         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.47e-05    |
|    value_loss           | 24.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 824          |
|    ep_rew_mean          | -150.1684    |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 4            |
|    time_elapsed         | 199          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.739396e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.135        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000294    |
|    learning_rate        | 1.81e-05     |
|    loss                 | 10.3         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.56e-05    |
|    value_loss           | 20.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 810           |
|    ep_rew_mean          | -150.68564    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 7.5066055e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.135         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000577      |
|    learning_rate        | 1.81e-05      |
|    loss                 | 11            |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.28e-05     |
|    value_loss           | 22            |
-------------------------------------------
mean_reward
-115.70805
[I 2022-04-25 19:08:56,143] Trial 50 finished with value: -115.70805358886719 and parameters: {'batch_size': 60707, 'gamma': 0.9208422150929056, 'learning_rate': 1.8126534098850605e-05, 'clip_range': 0.13507749889951032, 'gae_lambda': 0.9381154973053581}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 53354, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_52
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 805        |
|    ep_rew_mean     | -141.05754 |
| time/              |            |
|    fps             | 517        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -146.06973    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.8729529e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.137         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00113      |
|    learning_rate        | 1.81e-05      |
|    loss                 | 13.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.63e-05     |
|    value_loss           | 27.2          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 831            |
|    ep_rew_mean          | -146.43178     |
| time/                   |                |
|    fps                  | 494            |
|    iterations           | 3              |
|    time_elapsed         | 149            |
|    total_timesteps      | 73728          |
| train/                  |                |
|    approx_kl            | 1.12525115e-07 |
|    clip_fraction        | 0              |
|    clip_range           | 0.137          |
|    entropy_loss         | -3.89          |
|    explained_variance   | -0.00351       |
|    learning_rate        | 1.81e-05       |
|    loss                 | 10.6           |
|    n_updates            | 20             |
|    policy_gradient_loss | -1.63e-05      |
|    value_loss           | 21.2           |
--------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 831          |
|    ep_rew_mean          | -146.39455   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 4            |
|    time_elapsed         | 198          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.817733e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.137        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000239    |
|    learning_rate        | 1.81e-05     |
|    loss                 | 11.9         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.53e-05    |
|    value_loss           | 23.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 835           |
|    ep_rew_mean          | -152.598      |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0274865e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.137         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00162       |
|    learning_rate        | 1.81e-05      |
|    loss                 | 11.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.41e-05     |
|    value_loss           | 22.4          |
-------------------------------------------
mean_reward
-146.26358
[I 2022-04-25 19:13:28,877] Trial 51 finished with value: -146.26358032226562 and parameters: {'batch_size': 53354, 'gamma': 0.9236970102566523, 'learning_rate': 1.8094808034725993e-05, 'clip_range': 0.13672144248658238, 'gae_lambda': 0.937589446869225}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 63374, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_53
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 769        |
|    ep_rew_mean     | -170.24585 |
| time/              |            |
|    fps             | 507        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 817          |
|    ep_rew_mean          | -162.25487   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.948216e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.15         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00033     |
|    learning_rate        | 1.59e-05     |
|    loss                 | 12           |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.57e-05    |
|    value_loss           | 24           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -165.5308     |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.1118455e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.15          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00181      |
|    learning_rate        | 1.59e-05      |
|    loss                 | 11.6          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.15e-05     |
|    value_loss           | 23.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 811           |
|    ep_rew_mean          | -159.11272    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.3490417e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.15          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00239      |
|    learning_rate        | 1.59e-05      |
|    loss                 | 12.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.11e-05     |
|    value_loss           | 25            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 811           |
|    ep_rew_mean          | -163.39009    |
| time/                   |               |
|    fps                  | 490           |
|    iterations           | 5             |
|    time_elapsed         | 250           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 5.7186604e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.15          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000537     |
|    learning_rate        | 1.59e-05      |
|    loss                 | 12            |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.16e-05     |
|    value_loss           | 24            |
-------------------------------------------
mean_reward
-189.44548
[I 2022-04-25 19:18:01,007] Trial 52 finished with value: -189.4454803466797 and parameters: {'batch_size': 63374, 'gamma': 0.9206374317896573, 'learning_rate': 1.5877243855629785e-05, 'clip_range': 0.15017693383201272, 'gae_lambda': 0.9446058549933177}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 15128, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 9448
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_54
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 756        |
|    ep_rew_mean     | -165.20287 |
| time/              |            |
|    fps             | 498        |
|    iterations      | 1          |
|    time_elapsed    | 49         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 784          |
|    ep_rew_mean          | -170.57658   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 2            |
|    time_elapsed         | 99           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 4.768398e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.131        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00595     |
|    learning_rate        | 2.23e-05     |
|    loss                 | 12.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -6.53e-05    |
|    value_loss           | 24.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 790           |
|    ep_rew_mean          | -157.82153    |
| time/                   |               |
|    fps                  | 490           |
|    iterations           | 3             |
|    time_elapsed         | 150           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 3.2997377e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.131         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00615      |
|    learning_rate        | 2.23e-05      |
|    loss                 | 13.8          |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.7e-05      |
|    value_loss           | 27.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 804           |
|    ep_rew_mean          | -159.9047     |
| time/                   |               |
|    fps                  | 486           |
|    iterations           | 4             |
|    time_elapsed         | 202           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.4761998e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.131         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00412      |
|    learning_rate        | 2.23e-05      |
|    loss                 | 13.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -4.74e-05     |
|    value_loss           | 27.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 803           |
|    ep_rew_mean          | -156.69704    |
| time/                   |               |
|    fps                  | 486           |
|    iterations           | 5             |
|    time_elapsed         | 252           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.6251373e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.131         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00284      |
|    learning_rate        | 2.23e-05      |
|    loss                 | 15.4          |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.84e-05     |
|    value_loss           | 33.2          |
-------------------------------------------
mean_reward
-177.30359
[I 2022-04-25 19:22:32,239] Trial 53 finished with value: -177.3035888671875 and parameters: {'batch_size': 15128, 'gamma': 0.9274954262768498, 'learning_rate': 2.2292958963234792e-05, 'clip_range': 0.1312784744759921, 'gae_lambda': 0.9518212673394879}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 73419, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_55
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 826        |
|    ep_rew_mean     | -125.86448 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -136.92989    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.5331898e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.167         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0036       |
|    learning_rate        | 1.88e-05      |
|    loss                 | 13.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.46e-05     |
|    value_loss           | 27.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 804           |
|    ep_rew_mean          | -142.63696    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.0054889e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.167         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00289      |
|    learning_rate        | 1.88e-05      |
|    loss                 | 12            |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.6e-05      |
|    value_loss           | 24.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 797          |
|    ep_rew_mean          | -149.09067   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 4            |
|    time_elapsed         | 198          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 7.334165e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.167        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00267     |
|    learning_rate        | 1.88e-05     |
|    loss                 | 12.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.35e-05    |
|    value_loss           | 25.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 816          |
|    ep_rew_mean          | -144.59476   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 5            |
|    time_elapsed         | 248          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.196165e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.167        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0036      |
|    learning_rate        | 1.88e-05     |
|    loss                 | 12.6         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.25e-05    |
|    value_loss           | 25.2         |
------------------------------------------
mean_reward
-256.53833
[I 2022-04-25 19:27:15,652] Trial 54 finished with value: -256.538330078125 and parameters: {'batch_size': 73419, 'gamma': 0.9072766209901793, 'learning_rate': 1.8841668586352495e-05, 'clip_range': 0.16723752270095205, 'gae_lambda': 0.9707590575635757}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 58562, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_56
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 799        |
|    ep_rew_mean     | -180.48705 |
| time/              |            |
|    fps             | 529        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 844          |
|    ep_rew_mean          | -159.8295    |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 4.492904e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.113        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000456     |
|    learning_rate        | 1.24e-05     |
|    loss                 | 22.5         |
|    n_updates            | 10           |
|    policy_gradient_loss | -1.82e-05    |
|    value_loss           | 45.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -162.92706    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 3.5863195e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.113         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00018      |
|    learning_rate        | 1.24e-05      |
|    loss                 | 26.9          |
|    n_updates            | 20            |
|    policy_gradient_loss | -8.44e-06     |
|    value_loss           | 53.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 884           |
|    ep_rew_mean          | -158.55069    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 3.1361804e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.113         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000198      |
|    learning_rate        | 1.24e-05      |
|    loss                 | 27.2          |
|    n_updates            | 30            |
|    policy_gradient_loss | -7.27e-06     |
|    value_loss           | 54.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 883          |
|    ep_rew_mean          | -146.51717   |
| time/                   |              |
|    fps                  | 505          |
|    iterations           | 5            |
|    time_elapsed         | 243          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 3.023403e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.113        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000481    |
|    learning_rate        | 1.24e-05     |
|    loss                 | 30.3         |
|    n_updates            | 40           |
|    policy_gradient_loss | -8.27e-06    |
|    value_loss           | 60.7         |
------------------------------------------
mean_reward
-207.48418
[I 2022-04-25 19:31:50,109] Trial 55 finished with value: -207.4841766357422 and parameters: {'batch_size': 58562, 'gamma': 0.9683479166233397, 'learning_rate': 1.2428754429691264e-05, 'clip_range': 0.11278750400865327, 'gae_lambda': 0.9611365228189777}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 32185, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_57
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 836        |
|    ep_rew_mean     | -149.14558 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 841          |
|    ep_rew_mean          | -149.65157   |
| time/                   |              |
|    fps                  | 517          |
|    iterations           | 2            |
|    time_elapsed         | 95           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.586802e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.151        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00194     |
|    learning_rate        | 1.63e-05     |
|    loss                 | 9.31         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.98e-05    |
|    value_loss           | 18.7         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 831         |
|    ep_rew_mean          | -146.02351  |
| time/                   |             |
|    fps                  | 503         |
|    iterations           | 3           |
|    time_elapsed         | 146         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 6.68709e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.151       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.00231    |
|    learning_rate        | 1.63e-05    |
|    loss                 | 9.72        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.59e-05   |
|    value_loss           | 19.5        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 823           |
|    ep_rew_mean          | -153.1438     |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 4             |
|    time_elapsed         | 196           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.1470124e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.151         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00449      |
|    learning_rate        | 1.63e-05      |
|    loss                 | 11.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.13e-05     |
|    value_loss           | 23.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 856          |
|    ep_rew_mean          | -144.87662   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 5            |
|    time_elapsed         | 245          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 3.960789e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.151        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00267     |
|    learning_rate        | 1.63e-05     |
|    loss                 | 13.4         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.09e-05    |
|    value_loss           | 26.8         |
------------------------------------------
mean_reward
-124.161476
[I 2022-04-25 19:36:18,328] Trial 56 finished with value: -124.1614761352539 and parameters: {'batch_size': 32185, 'gamma': 0.9333712948651116, 'learning_rate': 1.6258418336865046e-05, 'clip_range': 0.15141965198016863, 'gae_lambda': 0.9202391571104307}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 33563, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_58
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 879        |
|    ep_rew_mean     | -169.72772 |
| time/              |            |
|    fps             | 533        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -165.22807    |
| time/                   |               |
|    fps                  | 517           |
|    iterations           | 2             |
|    time_elapsed         | 95            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.3201984e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.291         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00141      |
|    learning_rate        | 1.41e-05      |
|    loss                 | 10.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.8e-05      |
|    value_loss           | 20.9          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 832         |
|    ep_rew_mean          | -164.98793  |
| time/                   |             |
|    fps                  | 507         |
|    iterations           | 3           |
|    time_elapsed         | 145         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 7.74647e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.291       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.000195   |
|    learning_rate        | 1.41e-05    |
|    loss                 | 10.3        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.25e-05   |
|    value_loss           | 20.7        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 828          |
|    ep_rew_mean          | -164.00067   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 6.470509e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.291        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00265     |
|    learning_rate        | 1.41e-05     |
|    loss                 | 10.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.18e-05    |
|    value_loss           | 21.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -149.7042    |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 5            |
|    time_elapsed         | 245          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 6.033952e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.291        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00117     |
|    learning_rate        | 1.41e-05     |
|    loss                 | 11           |
|    n_updates            | 40           |
|    policy_gradient_loss | -9.34e-06    |
|    value_loss           | 22.1         |
------------------------------------------
mean_reward
-202.72151
[I 2022-04-25 19:40:43,936] Trial 57 finished with value: -202.7215118408203 and parameters: {'batch_size': 33563, 'gamma': 0.9326110700244763, 'learning_rate': 1.4149404483161344e-05, 'clip_range': 0.2906578269772998, 'gae_lambda': 0.9189369783990233}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 24640, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_59
------------------------------------
| rollout/           |             |
|    ep_len_mean     | 795         |
|    ep_rew_mean     | -124.379456 |
| time/              |             |
|    fps             | 510         |
|    iterations      | 1           |
|    time_elapsed    | 48          |
|    total_timesteps | 24576       |
------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 821           |
|    ep_rew_mean          | -137.82806    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0500662e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00305      |
|    learning_rate        | 1.62e-05      |
|    loss                 | 11.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.1e-05      |
|    value_loss           | 23.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 820          |
|    ep_rew_mean          | -144.2992    |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.221631e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.156        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00324     |
|    learning_rate        | 1.62e-05     |
|    loss                 | 9.67         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.53e-05    |
|    value_loss           | 19.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -150.77321   |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 5.091715e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.156        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00193     |
|    learning_rate        | 1.62e-05     |
|    loss                 | 9.45         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.16e-05    |
|    value_loss           | 18.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 829           |
|    ep_rew_mean          | -151.25044    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.9592927e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.156         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00273      |
|    learning_rate        | 1.62e-05      |
|    loss                 | 11.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.19e-05     |
|    value_loss           | 22.2          |
-------------------------------------------
mean_reward
-184.68745
[I 2022-04-25 19:45:11,465] Trial 58 finished with value: -184.6874542236328 and parameters: {'batch_size': 24640, 'gamma': 0.9141801161018409, 'learning_rate': 1.6208920262841606e-05, 'clip_range': 0.1564848896259722, 'gae_lambda': 0.9276808226433992}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 18164, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 6412
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_60
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 779       |
|    ep_rew_mean     | -137.0682 |
| time/              |           |
|    fps             | 505       |
|    iterations      | 1         |
|    time_elapsed    | 48        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 786           |
|    ep_rew_mean          | -142.15186    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4006005e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.191         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000962      |
|    learning_rate        | 1.14e-05      |
|    loss                 | 11.1          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.69e-05     |
|    value_loss           | 20.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 802          |
|    ep_rew_mean          | -147.36389   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 3            |
|    time_elapsed         | 149          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.905891e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.191        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.0027       |
|    learning_rate        | 1.14e-05     |
|    loss                 | 9.44         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.91e-05    |
|    value_loss           | 19.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 818           |
|    ep_rew_mean          | -155.34833    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.7919934e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.191         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000875      |
|    learning_rate        | 1.14e-05      |
|    loss                 | 8.94          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.58e-05     |
|    value_loss           | 17.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 831           |
|    ep_rew_mean          | -158.79874    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 9.0844125e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.191         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00225       |
|    learning_rate        | 1.14e-05      |
|    loss                 | 9.48          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.07e-05     |
|    value_loss           | 19.6          |
-------------------------------------------
mean_reward
-212.74971
[I 2022-04-25 19:49:45,511] Trial 59 finished with value: -212.7497100830078 and parameters: {'batch_size': 18164, 'gamma': 0.9275540570093994, 'learning_rate': 1.1424224813540096e-05, 'clip_range': 0.19137926731518667, 'gae_lambda': 0.910287981835961}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 23494, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 1082
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_61
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 829        |
|    ep_rew_mean     | -178.46231 |
| time/              |            |
|    fps             | 539        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 873           |
|    ep_rew_mean          | -167.48228    |
| time/                   |               |
|    fps                  | 516           |
|    iterations           | 2             |
|    time_elapsed         | 95            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 5.7957607e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.24          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.003        |
|    learning_rate        | 1.02e-05      |
|    loss                 | 9.12          |
|    n_updates            | 10            |
|    policy_gradient_loss | -1.81e-05     |
|    value_loss           | 19.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 861           |
|    ep_rew_mean          | -173.1055     |
| time/                   |               |
|    fps                  | 505           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.1004625e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.24          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00093      |
|    learning_rate        | 1.02e-05      |
|    loss                 | 8.03          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.04e-05     |
|    value_loss           | 16.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 849           |
|    ep_rew_mean          | -169.8572     |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 3.9594262e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.24          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000596     |
|    learning_rate        | 1.02e-05      |
|    loss                 | 9.95          |
|    n_updates            | 30            |
|    policy_gradient_loss | -8.86e-06     |
|    value_loss           | 17.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 830           |
|    ep_rew_mean          | -150.62914    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.4461423e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.24          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000107      |
|    learning_rate        | 1.02e-05      |
|    loss                 | 11.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -9.23e-06     |
|    value_loss           | 21            |
-------------------------------------------
mean_reward
-159.75937
[I 2022-04-25 19:54:20,000] Trial 60 finished with value: -159.75936889648438 and parameters: {'batch_size': 23494, 'gamma': 0.9434521557269887, 'learning_rate': 1.0152163756418992e-05, 'clip_range': 0.23957311448810129, 'gae_lambda': 0.9025903267751519}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 42978, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_62
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 848        |
|    ep_rew_mean     | -153.14091 |
| time/              |            |
|    fps             | 510        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 833          |
|    ep_rew_mean          | -160.209     |
| time/                   |              |
|    fps                  | 488          |
|    iterations           | 2            |
|    time_elapsed         | 100          |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.645293e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.141        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00175      |
|    learning_rate        | 1.69e-05     |
|    loss                 | 28.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.37e-05    |
|    value_loss           | 56.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 827           |
|    ep_rew_mean          | -148.1071     |
| time/                   |               |
|    fps                  | 485           |
|    iterations           | 3             |
|    time_elapsed         | 151           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.3410382e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.141         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00191       |
|    learning_rate        | 1.69e-05      |
|    loss                 | 29.9          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.12e-05     |
|    value_loss           | 59.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 840           |
|    ep_rew_mean          | -145.95172    |
| time/                   |               |
|    fps                  | 485           |
|    iterations           | 4             |
|    time_elapsed         | 202           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.9505616e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.141         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000293     |
|    learning_rate        | 1.69e-05      |
|    loss                 | 28.2          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.21e-05     |
|    value_loss           | 56.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -133.94453   |
| time/                   |              |
|    fps                  | 487          |
|    iterations           | 5            |
|    time_elapsed         | 252          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.474714e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.141        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00135      |
|    learning_rate        | 1.69e-05     |
|    loss                 | 26.8         |
|    n_updates            | 40           |
|    policy_gradient_loss | -7.78e-06    |
|    value_loss           | 53.6         |
------------------------------------------
mean_reward
-256.8425
[I 2022-04-25 19:58:59,527] Trial 61 finished with value: -256.8424987792969 and parameters: {'batch_size': 42978, 'gamma': 0.9996474652690929, 'learning_rate': 1.691950685648576e-05, 'clip_range': 0.1414601941606924, 'gae_lambda': 0.9363180827595233}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 30656, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_63
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 741        |
|    ep_rew_mean     | -158.51999 |
| time/              |            |
|    fps             | 512        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 784           |
|    ep_rew_mean          | -157.65582    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4995021e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.13          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000709     |
|    learning_rate        | 1.91e-05      |
|    loss                 | 16.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.29e-05     |
|    value_loss           | 33.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 799           |
|    ep_rew_mean          | -161.15517    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.0205016e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.13          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00129      |
|    learning_rate        | 1.91e-05      |
|    loss                 | 13.6          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.62e-05     |
|    value_loss           | 27.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 828           |
|    ep_rew_mean          | -151.53018    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 7.9414654e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.13          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00252      |
|    learning_rate        | 1.91e-05      |
|    loss                 | 13.1          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.33e-05     |
|    value_loss           | 26.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 842          |
|    ep_rew_mean          | -150.3131    |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 246          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.873799e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.13         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0009      |
|    learning_rate        | 1.91e-05     |
|    loss                 | 13.4         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.5e-05     |
|    value_loss           | 26.8         |
------------------------------------------
mean_reward
-134.19812
[I 2022-04-25 20:03:28,441] Trial 62 finished with value: -134.1981201171875 and parameters: {'batch_size': 30656, 'gamma': 0.9256079635838996, 'learning_rate': 1.909150876054807e-05, 'clip_range': 0.13002783483574173, 'gae_lambda': 0.9499404043267267}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 30559, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_64
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 832        |
|    ep_rew_mean     | -139.85866 |
| time/              |            |
|    fps             | 525        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 856           |
|    ep_rew_mean          | -149.36894    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4220132e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.123         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00331       |
|    learning_rate        | 1.91e-05      |
|    loss                 | 10.3          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.53e-05     |
|    value_loss           | 20.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 839          |
|    ep_rew_mean          | -148.52734   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 3            |
|    time_elapsed         | 146          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 7.983666e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.123        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00247     |
|    learning_rate        | 1.91e-05     |
|    loss                 | 10.6         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.49e-05    |
|    value_loss           | 21.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 846         |
|    ep_rew_mean          | -151.99654  |
| time/                   |             |
|    fps                  | 497         |
|    iterations           | 4           |
|    time_elapsed         | 197         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 8.77529e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.123       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.000551    |
|    learning_rate        | 1.91e-05    |
|    loss                 | 10.3        |
|    n_updates            | 30          |
|    policy_gradient_loss | -1.61e-05   |
|    value_loss           | 20.7        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 836          |
|    ep_rew_mean          | -152.89252   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 246          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 9.064873e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.123        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00167     |
|    learning_rate        | 1.91e-05     |
|    loss                 | 9.7          |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.54e-05    |
|    value_loss           | 19.4         |
------------------------------------------
mean_reward
-189.66148
[I 2022-04-25 20:07:53,464] Trial 63 finished with value: -189.66148376464844 and parameters: {'batch_size': 30559, 'gamma': 0.9252112881541555, 'learning_rate': 1.9051976165782363e-05, 'clip_range': 0.122769307250902, 'gae_lambda': 0.923087885566044}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 13095, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 11481
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_65
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 787        |
|    ep_rew_mean     | -154.59319 |
| time/              |            |
|    fps             | 500        |
|    iterations      | 1          |
|    time_elapsed    | 49         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 823           |
|    ep_rew_mean          | -161.19814    |
| time/                   |               |
|    fps                  | 508           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.5738524e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.162         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0024       |
|    learning_rate        | 1.4e-05       |
|    loss                 | 13.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.19e-05     |
|    value_loss           | 28.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 839           |
|    ep_rew_mean          | -160.75934    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.7662032e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.162         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000125     |
|    learning_rate        | 1.4e-05       |
|    loss                 | 11.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.47e-05     |
|    value_loss           | 22.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 848          |
|    ep_rew_mean          | -155.91289   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 2.051664e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.162        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000242    |
|    learning_rate        | 1.4e-05      |
|    loss                 | 10.2         |
|    n_updates            | 30           |
|    policy_gradient_loss | -2.56e-05    |
|    value_loss           | 21           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 860           |
|    ep_rew_mean          | -165.87878    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.1556912e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.162         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00141      |
|    learning_rate        | 1.4e-05       |
|    loss                 | 11.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.34e-05     |
|    value_loss           | 22.7          |
-------------------------------------------
mean_reward
-211.15735
[I 2022-04-25 20:12:28,263] Trial 64 finished with value: -211.1573486328125 and parameters: {'batch_size': 13095, 'gamma': 0.9212834011483182, 'learning_rate': 1.4041234509667277e-05, 'clip_range': 0.1623852571687255, 'gae_lambda': 0.945615534424827}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 35985, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_66
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 829        |
|    ep_rew_mean     | -139.80588 |
| time/              |            |
|    fps             | 519        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 788          |
|    ep_rew_mean          | -146.09215   |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.731351e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.151        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -5.72e-06    |
|    learning_rate        | 1.49e-05     |
|    loss                 | 10.8         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.67e-05    |
|    value_loss           | 21.7         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 802         |
|    ep_rew_mean          | -150.53195  |
| time/                   |             |
|    fps                  | 503         |
|    iterations           | 3           |
|    time_elapsed         | 146         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 4.99446e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.151       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.0008      |
|    learning_rate        | 1.49e-05    |
|    loss                 | 9.82        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.12e-05   |
|    value_loss           | 19.7        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 801           |
|    ep_rew_mean          | -158.80855    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.2423275e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.151         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 2.44e-05      |
|    learning_rate        | 1.49e-05      |
|    loss                 | 9.78          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.25e-05     |
|    value_loss           | 19.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 819          |
|    ep_rew_mean          | -152.41527   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 6.254171e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.151        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000271     |
|    learning_rate        | 1.49e-05     |
|    loss                 | 10.5         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.29e-05    |
|    value_loss           | 21           |
------------------------------------------
mean_reward
-170.89412
[I 2022-04-25 20:16:57,956] Trial 65 finished with value: -170.8941192626953 and parameters: {'batch_size': 35985, 'gamma': 0.9160929321685344, 'learning_rate': 1.4925680958358791e-05, 'clip_range': 0.15135014590705892, 'gae_lambda': 0.9301968359525542}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 19514, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 5062
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_67
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 737        |
|    ep_rew_mean     | -168.77441 |
| time/              |            |
|    fps             | 514        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 773          |
|    ep_rew_mean          | -153.63248   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 6.237096e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.11         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00813     |
|    learning_rate        | 2.24e-05     |
|    loss                 | 6.33         |
|    n_updates            | 10           |
|    policy_gradient_loss | -7.26e-05    |
|    value_loss           | 12.3         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 795        |
|    ep_rew_mean          | -150.99893 |
| time/                   |            |
|    fps                  | 492        |
|    iterations           | 3          |
|    time_elapsed         | 149        |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 3.9949e-07 |
|    clip_fraction        | 0          |
|    clip_range           | 0.11       |
|    entropy_loss         | -3.89      |
|    explained_variance   | -0.00181   |
|    learning_rate        | 2.24e-05   |
|    loss                 | 5.7        |
|    n_updates            | 20         |
|    policy_gradient_loss | -3.95e-05  |
|    value_loss           | 12.1       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 804          |
|    ep_rew_mean          | -155.12273   |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 4            |
|    time_elapsed         | 199          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.056304e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.11         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0027      |
|    learning_rate        | 2.24e-05     |
|    loss                 | 5.48         |
|    n_updates            | 30           |
|    policy_gradient_loss | -3.62e-05    |
|    value_loss           | 11.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 821           |
|    ep_rew_mean          | -144.19775    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.5296443e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.11          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00361      |
|    learning_rate        | 2.24e-05      |
|    loss                 | 5.34          |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.41e-05     |
|    value_loss           | 11.3          |
-------------------------------------------
mean_reward
-233.14531
[I 2022-04-25 20:21:33,592] Trial 66 finished with value: -233.1453094482422 and parameters: {'batch_size': 19514, 'gamma': 0.9381525777248961, 'learning_rate': 2.2415133748797707e-05, 'clip_range': 0.10979896884862694, 'gae_lambda': 0.8007985616638911}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 48885, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_68
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 792        |
|    ep_rew_mean     | -146.16634 |
| time/              |            |
|    fps             | 532        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -152.37355    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0771328e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 6.11e-05      |
|    learning_rate        | 1.61e-05      |
|    loss                 | 10.5          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.01e-05     |
|    value_loss           | 21.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 826           |
|    ep_rew_mean          | -153.62532    |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 6.2316154e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000542      |
|    learning_rate        | 1.61e-05      |
|    loss                 | 9.62          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.26e-05     |
|    value_loss           | 19.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 837           |
|    ep_rew_mean          | -159.8168     |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 4             |
|    time_elapsed         | 194           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 5.5964243e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00041       |
|    learning_rate        | 1.61e-05      |
|    loss                 | 12.8          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.39e-05     |
|    value_loss           | 25.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 836           |
|    ep_rew_mean          | -159.97745    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 6.3332365e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.0016        |
|    learning_rate        | 1.61e-05      |
|    loss                 | 9.83          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.24e-05     |
|    value_loss           | 19.7          |
-------------------------------------------
mean_reward
-104.77965
[I 2022-04-25 20:26:05,025] Trial 67 finished with value: -104.77964782714844 and parameters: {'batch_size': 48885, 'gamma': 0.9287775062896944, 'learning_rate': 1.612301369141904e-05, 'clip_range': 0.399465706685165, 'gae_lambda': 0.9145829566002853}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 47230, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_69
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 796        |
|    ep_rew_mean     | -160.55202 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -156.48439    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.2091914e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.378         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00371      |
|    learning_rate        | 1.59e-05      |
|    loss                 | 7.38          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.15e-05     |
|    value_loss           | 14.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 818          |
|    ep_rew_mean          | -156.20317   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.041105e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.378        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00106     |
|    learning_rate        | 1.59e-05     |
|    loss                 | 8.43         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.6e-05     |
|    value_loss           | 16.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 837          |
|    ep_rew_mean          | -150.21785   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 6.404541e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.378        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00193     |
|    learning_rate        | 1.59e-05     |
|    loss                 | 7.24         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.2e-05     |
|    value_loss           | 14.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 821           |
|    ep_rew_mean          | -145.3434     |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 6.8704445e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.378         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00192      |
|    learning_rate        | 1.59e-05      |
|    loss                 | 7.56          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.41e-05     |
|    value_loss           | 15.2          |
-------------------------------------------
mean_reward
-186.23943
[I 2022-04-25 20:30:36,953] Trial 68 finished with value: -186.2394256591797 and parameters: {'batch_size': 47230, 'gamma': 0.9324866291378464, 'learning_rate': 1.591110114019995e-05, 'clip_range': 0.37812743041043034, 'gae_lambda': 0.8789713386531589}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 51367, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_70
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 819       |
|    ep_rew_mean     | -166.7201 |
| time/              |           |
|    fps             | 534       |
|    iterations      | 1         |
|    time_elapsed    | 46        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 816           |
|    ep_rew_mean          | -175.15776    |
| time/                   |               |
|    fps                  | 508           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.5797075e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.342         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000343     |
|    learning_rate        | 1.75e-05      |
|    loss                 | 10.1          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.42e-05     |
|    value_loss           | 20.2          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 798         |
|    ep_rew_mean          | -160.18405  |
| time/                   |             |
|    fps                  | 501         |
|    iterations           | 3           |
|    time_elapsed         | 147         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 9.70346e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.342       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.000186   |
|    learning_rate        | 1.75e-05    |
|    loss                 | 9.05        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.51e-05   |
|    value_loss           | 18.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 818          |
|    ep_rew_mean          | -156.18083   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.760496e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.342        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000241     |
|    learning_rate        | 1.75e-05     |
|    loss                 | 9.87         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.62e-05    |
|    value_loss           | 19.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -149.7407     |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 8.8439265e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.342         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00145       |
|    learning_rate        | 1.75e-05      |
|    loss                 | 8.07          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.51e-05     |
|    value_loss           | 16.2          |
-------------------------------------------
mean_reward
-160.5415
[I 2022-04-25 20:35:03,887] Trial 69 finished with value: -160.54150390625 and parameters: {'batch_size': 51367, 'gamma': 0.9350992944204164, 'learning_rate': 1.7538772067163887e-05, 'clip_range': 0.34222115085339844, 'gae_lambda': 0.904392548455071}. Best is trial 46 with value: -95.40400695800781.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 39773, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_71
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 800        |
|    ep_rew_mean     | -141.92194 |
| time/              |            |
|    fps             | 511        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 794          |
|    ep_rew_mean          | -148.308     |
| time/                   |              |
|    fps                  | 503          |
|    iterations           | 2            |
|    time_elapsed         | 97           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 5.051455e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.28         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00214     |
|    learning_rate        | 1.24e-05     |
|    loss                 | 11.7         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.1e-05     |
|    value_loss           | 23.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 800          |
|    ep_rew_mean          | -145.73375   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 4.398559e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.28         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00171     |
|    learning_rate        | 1.24e-05     |
|    loss                 | 10.4         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.24e-05    |
|    value_loss           | 20.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 798          |
|    ep_rew_mean          | -159.14471   |
| time/                   |              |
|    fps                  | 493          |
|    iterations           | 4            |
|    time_elapsed         | 199          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 4.132744e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.28         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00274     |
|    learning_rate        | 1.24e-05     |
|    loss                 | 11           |
|    n_updates            | 30           |
|    policy_gradient_loss | -9.78e-06    |
|    value_loss           | 21.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 799           |
|    ep_rew_mean          | -156.72139    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.9331812e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.28          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000424      |
|    learning_rate        | 1.24e-05      |
|    loss                 | 11.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -7.63e-06     |
|    value_loss           | 23.4          |
-------------------------------------------
mean_reward
-136.95401
[I 2022-04-25 20:39:30,902] Trial 70 finished with value: -136.95401000976562 and parameters: {'batch_size': 39773, 'gamma': 0.9291054445602465, 'learning_rate': 1.2421727434905313e-05, 'clip_range': 0.2795629370963838, 'gae_lambda': 0.915673350063157}. Best is trial 46 with value: -95.40400695800781.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 28815, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_72
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 749        |
|    ep_rew_mean     | -166.55997 |
| time/              |            |
|    fps             | 504        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 778           |
|    ep_rew_mean          | -163.86172    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.2425396e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00226      |
|    learning_rate        | 1.96e-05      |
|    loss                 | 20.2          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.97e-05     |
|    value_loss           | 40.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 805           |
|    ep_rew_mean          | -165.08719    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 7.5934324e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00203      |
|    learning_rate        | 1.96e-05      |
|    loss                 | 21.9          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.43e-05     |
|    value_loss           | 43.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 815          |
|    ep_rew_mean          | -165.98376   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 7.523098e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.399        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0011      |
|    learning_rate        | 1.96e-05     |
|    loss                 | 21.4         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.41e-05    |
|    value_loss           | 43           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 842          |
|    ep_rew_mean          | -165.37833   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 246          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.032213e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.399        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000993    |
|    learning_rate        | 1.96e-05     |
|    loss                 | 18.8         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.18e-05    |
|    value_loss           | 37.6         |
------------------------------------------
mean_reward
-88.24409
[I 2022-04-25 20:43:57,272] Trial 71 finished with value: -88.24408721923828 and parameters: {'batch_size': 28815, 'gamma': 0.9254533886157719, 'learning_rate': 1.958232389849691e-05, 'clip_range': 0.3991136793393521, 'gae_lambda': 0.9893567426332022}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 25036, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_73
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 832        |
|    ep_rew_mean     | -167.78221 |
| time/              |            |
|    fps             | 515        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 812           |
|    ep_rew_mean          | -159.0846     |
| time/                   |               |
|    fps                  | 508           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.7412337e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.397         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000768     |
|    learning_rate        | 2.64e-05      |
|    loss                 | 15.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.89e-05     |
|    value_loss           | 31.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 824           |
|    ep_rew_mean          | -162.71574    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.1923355e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.397         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000911     |
|    learning_rate        | 2.64e-05      |
|    loss                 | 17.4          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.2e-05      |
|    value_loss           | 34.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 827          |
|    ep_rew_mean          | -162.29308   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.738869e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.397        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00302     |
|    learning_rate        | 2.64e-05     |
|    loss                 | 14           |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.42e-05    |
|    value_loss           | 28.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 829           |
|    ep_rew_mean          | -159.83714    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 9.6268195e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.397         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00133       |
|    learning_rate        | 2.64e-05      |
|    loss                 | 16.8          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.67e-05     |
|    value_loss           | 33.8          |
-------------------------------------------
mean_reward
-187.52762
[I 2022-04-25 20:48:32,314] Trial 72 finished with value: -187.52761840820312 and parameters: {'batch_size': 25036, 'gamma': 0.9120138345304816, 'learning_rate': 2.6387537385991365e-05, 'clip_range': 0.39704609607538527, 'gae_lambda': 0.9889721008279371}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 57698, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_74
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 778        |
|    ep_rew_mean     | -154.80121 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 797          |
|    ep_rew_mean          | -140.8035    |
| time/                   |              |
|    fps                  | 506          |
|    iterations           | 2            |
|    time_elapsed         | 97           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.442253e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.372        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000828    |
|    learning_rate        | 1.54e-05     |
|    loss                 | 15.6         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.52e-05    |
|    value_loss           | 31.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 806           |
|    ep_rew_mean          | -155.63675    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.9476104e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.372         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000657      |
|    learning_rate        | 1.54e-05      |
|    loss                 | 17.1          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.2e-05      |
|    value_loss           | 34.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 829           |
|    ep_rew_mean          | -158.97704    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 4             |
|    time_elapsed         | 196           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.6204757e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.372         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000394      |
|    learning_rate        | 1.54e-05      |
|    loss                 | 16.3          |
|    n_updates            | 30            |
|    policy_gradient_loss | -9.01e-06     |
|    value_loss           | 32.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -163.72896    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.3614516e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.372         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00063       |
|    learning_rate        | 1.54e-05      |
|    loss                 | 15.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -9.61e-06     |
|    value_loss           | 31.4          |
-------------------------------------------
mean_reward
-127.61588
[I 2022-04-25 20:53:02,576] Trial 73 finished with value: -127.61588287353516 and parameters: {'batch_size': 57698, 'gamma': 0.9188517746700977, 'learning_rate': 1.5361440559537853e-05, 'clip_range': 0.37221797491668646, 'gae_lambda': 0.9765328251613811}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 60450, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_75
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 889        |
|    ep_rew_mean     | -164.10315 |
| time/              |            |
|    fps             | 536        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 885           |
|    ep_rew_mean          | -174.13931    |
| time/                   |               |
|    fps                  | 518           |
|    iterations           | 2             |
|    time_elapsed         | 94            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4056181e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.372         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00161      |
|    learning_rate        | 1.7e-05       |
|    loss                 | 7.14          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.2e-05      |
|    value_loss           | 14.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 853          |
|    ep_rew_mean          | -157.74585   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 3            |
|    time_elapsed         | 146          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 8.389179e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.372        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00138     |
|    learning_rate        | 1.7e-05      |
|    loss                 | 7.7          |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.5e-05     |
|    value_loss           | 15.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 825          |
|    ep_rew_mean          | -157.34628   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 6.636886e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.372        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00107      |
|    learning_rate        | 1.7e-05      |
|    loss                 | 9.32         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.4e-05     |
|    value_loss           | 18.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -146.01118    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 5.7979683e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.372         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000616     |
|    learning_rate        | 1.7e-05       |
|    loss                 | 8.19          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.19e-05     |
|    value_loss           | 16.4          |
-------------------------------------------
mean_reward
-198.83127
[I 2022-04-25 20:57:33,874] Trial 74 finished with value: -198.83126831054688 and parameters: {'batch_size': 60450, 'gamma': 0.9178862021900361, 'learning_rate': 1.7003067385961584e-05, 'clip_range': 0.3716112394654438, 'gae_lambda': 0.8965429439891518}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 57304, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_76
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 829        |
|    ep_rew_mean     | -188.10683 |
| time/              |            |
|    fps             | 531        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 835          |
|    ep_rew_mean          | -170.16179   |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 6.775857e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.399        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00202     |
|    learning_rate        | 1.57e-05     |
|    loss                 | 20.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.22e-05    |
|    value_loss           | 40.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 842           |
|    ep_rew_mean          | -158.46124    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.6231435e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.399         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00555      |
|    learning_rate        | 1.57e-05      |
|    loss                 | 16.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.25e-05     |
|    value_loss           | 32.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 852          |
|    ep_rew_mean          | -158.73227   |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 5.228261e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.399        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00487     |
|    learning_rate        | 1.57e-05     |
|    loss                 | 15.5         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.16e-05    |
|    value_loss           | 31           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 838          |
|    ep_rew_mean          | -147.78146   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.328225e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.399        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00481     |
|    learning_rate        | 1.57e-05     |
|    loss                 | 16.4         |
|    n_updates            | 40           |
|    policy_gradient_loss | -7.19e-06    |
|    value_loss           | 32.8         |
------------------------------------------
mean_reward
-140.18152
[I 2022-04-25 21:02:12,328] Trial 75 finished with value: -140.1815185546875 and parameters: {'batch_size': 57304, 'gamma': 0.92230169036526, 'learning_rate': 1.566092306025366e-05, 'clip_range': 0.39880261654231075, 'gae_lambda': 0.9780708372019224}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 64757, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_77
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 817        |
|    ep_rew_mean     | -166.55173 |
| time/              |            |
|    fps             | 519        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -150.29349    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.1356877e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.364         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00216      |
|    learning_rate        | 2.1e-05       |
|    loss                 | 7.6           |
|    n_updates            | 10            |
|    policy_gradient_loss | -4.06e-05     |
|    value_loss           | 15.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 812           |
|    ep_rew_mean          | -147.04643    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.4012767e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.364         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00172      |
|    learning_rate        | 2.1e-05       |
|    loss                 | 7.85          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.08e-05     |
|    value_loss           | 15.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 810           |
|    ep_rew_mean          | -132.30275    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.1073523e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.364         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00108      |
|    learning_rate        | 2.1e-05       |
|    loss                 | 6.63          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.71e-05     |
|    value_loss           | 13.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 814           |
|    ep_rew_mean          | -134.64568    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.6014626e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.364         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00131       |
|    learning_rate        | 2.1e-05       |
|    loss                 | 7.62          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.24e-05     |
|    value_loss           | 15.3          |
-------------------------------------------
mean_reward
-141.13391
[I 2022-04-25 21:06:44,419] Trial 76 finished with value: -141.1339111328125 and parameters: {'batch_size': 64757, 'gamma': 0.908007995906261, 'learning_rate': 2.0977458927288057e-05, 'clip_range': 0.36405444623062716, 'gae_lambda': 0.8923937649185721}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 54575, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_78
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 879        |
|    ep_rew_mean     | -157.91798 |
| time/              |            |
|    fps             | 543        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 811          |
|    ep_rew_mean          | -163.26033   |
| time/                   |              |
|    fps                  | 499          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.218922e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.392        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00102     |
|    learning_rate        | 1.34e-05     |
|    loss                 | 22.2         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.09e-05    |
|    value_loss           | 44.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 802           |
|    ep_rew_mean          | -161.09511    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.6423036e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.392         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000927     |
|    learning_rate        | 1.34e-05      |
|    loss                 | 32            |
|    n_updates            | 20            |
|    policy_gradient_loss | -8.19e-06     |
|    value_loss           | 64.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 820          |
|    ep_rew_mean          | -155.43564   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 4            |
|    time_elapsed         | 197          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.261327e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.392        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000188    |
|    learning_rate        | 1.34e-05     |
|    loss                 | 23.8         |
|    n_updates            | 30           |
|    policy_gradient_loss | -6.38e-06    |
|    value_loss           | 47.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 833          |
|    ep_rew_mean          | -155.48618   |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 4.698571e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.392        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000469    |
|    learning_rate        | 1.34e-05     |
|    loss                 | 21.3         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.06e-05    |
|    value_loss           | 42.7         |
------------------------------------------
mean_reward
-200.40872
[I 2022-04-25 21:11:17,224] Trial 77 finished with value: -200.40872192382812 and parameters: {'batch_size': 54575, 'gamma': 0.9328997944900237, 'learning_rate': 1.3386885221756762e-05, 'clip_range': 0.39179547462570063, 'gae_lambda': 0.9846023310563738}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 43881, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_79
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 849        |
|    ep_rew_mean     | -152.26778 |
| time/              |            |
|    fps             | 538        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 849           |
|    ep_rew_mean          | -165.43034    |
| time/                   |               |
|    fps                  | 515           |
|    iterations           | 2             |
|    time_elapsed         | 95            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.7386387e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.384         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000345      |
|    learning_rate        | 2.3e-05       |
|    loss                 | 15.5          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.79e-05     |
|    value_loss           | 31.1          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 828         |
|    ep_rew_mean          | -161.64705  |
| time/                   |             |
|    fps                  | 500         |
|    iterations           | 3           |
|    time_elapsed         | 147         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 9.47354e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.384       |
|    entropy_loss         | -3.89       |
|    explained_variance   | -0.00012    |
|    learning_rate        | 2.3e-05     |
|    loss                 | 15.8        |
|    n_updates            | 20          |
|    policy_gradient_loss | -1.51e-05   |
|    value_loss           | 31.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 832         |
|    ep_rew_mean          | -164.22578  |
| time/                   |             |
|    fps                  | 503         |
|    iterations           | 4           |
|    time_elapsed         | 195         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 8.35765e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.384       |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.000967    |
|    learning_rate        | 2.3e-05     |
|    loss                 | 14.2        |
|    n_updates            | 30          |
|    policy_gradient_loss | -1.58e-05   |
|    value_loss           | 28.6        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 829          |
|    ep_rew_mean          | -167.03485   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 5            |
|    time_elapsed         | 245          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.903145e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.384        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000125     |
|    learning_rate        | 2.3e-05      |
|    loss                 | 13.9         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.39e-05    |
|    value_loss           | 27.8         |
------------------------------------------
mean_reward
-218.26819
[I 2022-04-25 21:15:43,038] Trial 78 finished with value: -218.2681884765625 and parameters: {'batch_size': 43881, 'gamma': 0.9199164745802755, 'learning_rate': 2.30013965394437e-05, 'clip_range': 0.3839038712570326, 'gae_lambda': 0.9746369533778971}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 72292, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_80
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 806        |
|    ep_rew_mean     | -134.40408 |
| time/              |            |
|    fps             | 519        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 853           |
|    ep_rew_mean          | -144.90707    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.8651917e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.345         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00296      |
|    learning_rate        | 2.04e-05      |
|    loss                 | 10.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.82e-05     |
|    value_loss           | 20.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -143.18199    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.3420262e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.345         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000768     |
|    learning_rate        | 2.04e-05      |
|    loss                 | 9.17          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.03e-05     |
|    value_loss           | 18.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 811           |
|    ep_rew_mean          | -147.90053    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.3017174e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.345         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00236      |
|    learning_rate        | 2.04e-05      |
|    loss                 | 9.66          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.77e-05     |
|    value_loss           | 19.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 808           |
|    ep_rew_mean          | -156.9914     |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.0496054e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.345         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -6.08e-06     |
|    learning_rate        | 2.04e-05      |
|    loss                 | 9.29          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.2e-05      |
|    value_loss           | 18.6          |
-------------------------------------------
mean_reward
-183.66043
[I 2022-04-25 21:20:22,599] Trial 79 finished with value: -183.66043090820312 and parameters: {'batch_size': 72292, 'gamma': 0.9269925396709112, 'learning_rate': 2.0368499322272188e-05, 'clip_range': 0.3449038962667288, 'gae_lambda': 0.917116268487404}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 61326, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_81
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 775        |
|    ep_rew_mean     | -162.68083 |
| time/              |            |
|    fps             | 532        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 803           |
|    ep_rew_mean          | -159.23648    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.8724192e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.378         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0017       |
|    learning_rate        | 1.83e-05      |
|    loss                 | 9.86          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.29e-05     |
|    value_loss           | 19.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 806          |
|    ep_rew_mean          | -156.33382   |
| time/                   |              |
|    fps                  | 503          |
|    iterations           | 3            |
|    time_elapsed         | 146          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 1.198132e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.378        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00261     |
|    learning_rate        | 1.83e-05     |
|    loss                 | 8.73         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.77e-05    |
|    value_loss           | 17.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 822           |
|    ep_rew_mean          | -144.60437    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.5304492e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.378         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000447     |
|    learning_rate        | 1.83e-05      |
|    loss                 | 8.9           |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.79e-05     |
|    value_loss           | 17.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 821           |
|    ep_rew_mean          | -136.1666     |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.2787254e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.378         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000687     |
|    learning_rate        | 1.83e-05      |
|    loss                 | 10.3          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.63e-05     |
|    value_loss           | 20.6          |
-------------------------------------------
mean_reward
-183.01941
[I 2022-04-25 21:24:53,092] Trial 80 finished with value: -183.0194091796875 and parameters: {'batch_size': 61326, 'gamma': 0.9301434788162977, 'learning_rate': 1.8253607514023482e-05, 'clip_range': 0.3780636714583525, 'gae_lambda': 0.9074390206543467}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 14676, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 9900
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_82
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 798        |
|    ep_rew_mean     | -154.02956 |
| time/              |            |
|    fps             | 513        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -152.35353    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.3524159e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.362         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00124       |
|    learning_rate        | 1.36e-05      |
|    loss                 | 15.2          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.54e-05     |
|    value_loss           | 30.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 804          |
|    ep_rew_mean          | -156.23611   |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 3            |
|    time_elapsed         | 147          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 9.635028e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.362        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00181     |
|    learning_rate        | 1.36e-05     |
|    loss                 | 18.6         |
|    n_updates            | 20           |
|    policy_gradient_loss | -2.23e-05    |
|    value_loss           | 37.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 831          |
|    ep_rew_mean          | -156.91443   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 4            |
|    time_elapsed         | 198          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.457776e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.362        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000312     |
|    learning_rate        | 1.36e-05     |
|    loss                 | 17.5         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.77e-05    |
|    value_loss           | 36.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 815           |
|    ep_rew_mean          | -159.69882    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.2271286e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.362         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000135      |
|    learning_rate        | 1.36e-05      |
|    loss                 | 18.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.31e-05     |
|    value_loss           | 35.9          |
-------------------------------------------
mean_reward
-159.60765
[I 2022-04-25 21:29:27,029] Trial 81 finished with value: -159.60765075683594 and parameters: {'batch_size': 14676, 'gamma': 0.924107920492465, 'learning_rate': 1.3643741405280776e-05, 'clip_range': 0.36246007279032827, 'gae_lambda': 0.9791527374488341}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 21254, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 3322
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_83
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 863        |
|    ep_rew_mean     | -159.90175 |
| time/              |            |
|    fps             | 526        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 845           |
|    ep_rew_mean          | -166.9397     |
| time/                   |               |
|    fps                  | 508           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.0611935e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.329         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00164      |
|    learning_rate        | 1.5e-05       |
|    loss                 | 14.6          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.84e-05     |
|    value_loss           | 28.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 823           |
|    ep_rew_mean          | -162.5318     |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.1491041e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.329         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.0014        |
|    learning_rate        | 1.5e-05       |
|    loss                 | 13.3          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.85e-05     |
|    value_loss           | 28            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -162.89053    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.1291293e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.329         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00222      |
|    learning_rate        | 1.5e-05       |
|    loss                 | 12.7          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.92e-05     |
|    value_loss           | 26.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 828           |
|    ep_rew_mean          | -156.53627    |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.1512069e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.329         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 9.07e-05      |
|    learning_rate        | 1.5e-05       |
|    loss                 | 14.6          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.81e-05     |
|    value_loss           | 29.8          |
-------------------------------------------
mean_reward
-157.05319
[I 2022-04-25 21:34:02,262] Trial 82 finished with value: -157.05319213867188 and parameters: {'batch_size': 21254, 'gamma': 0.9156738765594521, 'learning_rate': 1.5016122667421575e-05, 'clip_range': 0.32866538604360157, 'gae_lambda': 0.968896046404565}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 33892, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_84
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 827        |
|    ep_rew_mean     | -159.57559 |
| time/              |            |
|    fps             | 528        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 818           |
|    ep_rew_mean          | -147.02913    |
| time/                   |               |
|    fps                  | 509           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.3918018e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.253         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000449      |
|    learning_rate        | 8.89e-05      |
|    loss                 | 19.2          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000149     |
|    value_loss           | 38.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 827           |
|    ep_rew_mean          | -145.14743    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.0061975e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.253         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000993      |
|    learning_rate        | 8.89e-05      |
|    loss                 | 22.3          |
|    n_updates            | 20            |
|    policy_gradient_loss | -7.86e-05     |
|    value_loss           | 44.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -146.93738    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.2666961e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.253         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00213       |
|    learning_rate        | 8.89e-05      |
|    loss                 | 15            |
|    n_updates            | 30            |
|    policy_gradient_loss | -7.04e-05     |
|    value_loss           | 30.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 803           |
|    ep_rew_mean          | -143.24928    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4377438e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.253         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00414       |
|    learning_rate        | 8.89e-05      |
|    loss                 | 17            |
|    n_updates            | 40            |
|    policy_gradient_loss | -5.94e-05     |
|    value_loss           | 34.3          |
-------------------------------------------
mean_reward
-177.2579
[I 2022-04-25 21:38:27,148] Trial 83 finished with value: -177.25790405273438 and parameters: {'batch_size': 33892, 'gamma': 0.9184216113003657, 'learning_rate': 8.892738766683083e-05, 'clip_range': 0.2534909583551702, 'gae_lambda': 0.9874430963035254}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 17888, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 6688
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_85
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 792        |
|    ep_rew_mean     | -157.09529 |
| time/              |            |
|    fps             | 507        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 817           |
|    ep_rew_mean          | -162.65094    |
| time/                   |               |
|    fps                  | 507           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 3.2125928e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00112       |
|    learning_rate        | 1.68e-05      |
|    loss                 | 10.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -5.04e-05     |
|    value_loss           | 22.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 819           |
|    ep_rew_mean          | -153.95651    |
| time/                   |               |
|    fps                  | 500           |
|    iterations           | 3             |
|    time_elapsed         | 147           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.9763706e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000884      |
|    learning_rate        | 1.68e-05      |
|    loss                 | 10            |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.66e-05     |
|    value_loss           | 20.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 830           |
|    ep_rew_mean          | -155.62569    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.1747813e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00318       |
|    learning_rate        | 1.68e-05      |
|    loss                 | 11.8          |
|    n_updates            | 30            |
|    policy_gradient_loss | -3.11e-05     |
|    value_loss           | 24.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 861           |
|    ep_rew_mean          | -149.91815    |
| time/                   |               |
|    fps                  | 498           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.2391457e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.314         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000393      |
|    learning_rate        | 1.68e-05      |
|    loss                 | 12.5          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.83e-05     |
|    value_loss           | 24.2          |
-------------------------------------------
mean_reward
-209.11914
[I 2022-04-25 21:42:53,505] Trial 84 finished with value: -209.119140625 and parameters: {'batch_size': 17888, 'gamma': 0.9126459711783851, 'learning_rate': 1.678045411584231e-05, 'clip_range': 0.314297024963665, 'gae_lambda': 0.9569126440250352}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 96468, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_86
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 888        |
|    ep_rew_mean     | -145.75333 |
| time/              |            |
|    fps             | 528        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 833          |
|    ep_rew_mean          | -153.92114   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 1.137693e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.389        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00329     |
|    learning_rate        | 1.56e-05     |
|    loss                 | 17.3         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.66e-05    |
|    value_loss           | 34.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 839           |
|    ep_rew_mean          | -152.5361     |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 6.9548456e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00154      |
|    learning_rate        | 1.56e-05      |
|    loss                 | 19.2          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.14e-05     |
|    value_loss           | 38.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 808           |
|    ep_rew_mean          | -144.4191     |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.6163528e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00298      |
|    learning_rate        | 1.56e-05      |
|    loss                 | 21.3          |
|    n_updates            | 30            |
|    policy_gradient_loss | -9.12e-06     |
|    value_loss           | 42.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 813           |
|    ep_rew_mean          | -149.4929     |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 5.3718395e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.389         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00302      |
|    learning_rate        | 1.56e-05      |
|    loss                 | 20.6          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.18e-05     |
|    value_loss           | 41.3          |
-------------------------------------------
mean_reward
-208.0853
[I 2022-04-25 21:47:32,947] Trial 85 finished with value: -208.08529663085938 and parameters: {'batch_size': 96468, 'gamma': 0.9427647081704355, 'learning_rate': 1.5565154992371047e-05, 'clip_range': 0.38937405611841025, 'gae_lambda': 0.9664630213883982}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 50216, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_87
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 793        |
|    ep_rew_mean     | -206.53783 |
| time/              |            |
|    fps             | 514        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 796           |
|    ep_rew_mean          | -191.83287    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.0759762e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.14          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00145      |
|    learning_rate        | 1.97e-05      |
|    loss                 | 7.36          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.96e-05     |
|    value_loss           | 14.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 796           |
|    ep_rew_mean          | -169.80441    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.4826219e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.14          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000842     |
|    learning_rate        | 1.97e-05      |
|    loss                 | 5.77          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.12e-05     |
|    value_loss           | 11.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -156.0552     |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.6108001e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.14          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00268       |
|    learning_rate        | 1.97e-05      |
|    loss                 | 6.61          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.13e-05     |
|    value_loss           | 13.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 848           |
|    ep_rew_mean          | -152.3724     |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 5             |
|    time_elapsed         | 248           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4339457e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.14          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00452       |
|    learning_rate        | 1.97e-05      |
|    loss                 | 5.54          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.01e-05     |
|    value_loss           | 11.1          |
-------------------------------------------
mean_reward
-229.64294
[I 2022-04-25 21:52:06,231] Trial 86 finished with value: -229.6429443359375 and parameters: {'batch_size': 50216, 'gamma': 0.9036174389149995, 'learning_rate': 1.96690275598028e-05, 'clip_range': 0.14020419026192235, 'gae_lambda': 0.8511598731430476}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 75712, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_88
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 828        |
|    ep_rew_mean     | -153.62039 |
| time/              |            |
|    fps             | 535        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 865           |
|    ep_rew_mean          | -160.20093    |
| time/                   |               |
|    fps                  | 519           |
|    iterations           | 2             |
|    time_elapsed         | 94            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 7.7277946e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.144         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00219      |
|    learning_rate        | 1.19e-05      |
|    loss                 | 13.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.27e-05     |
|    value_loss           | 27.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 840          |
|    ep_rew_mean          | -150.72926   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 3            |
|    time_elapsed         | 145          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 4.020694e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.144        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00264      |
|    learning_rate        | 1.19e-05     |
|    loss                 | 11           |
|    n_updates            | 20           |
|    policy_gradient_loss | -9.77e-06    |
|    value_loss           | 22.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 839          |
|    ep_rew_mean          | -152.88016   |
| time/                   |              |
|    fps                  | 501          |
|    iterations           | 4            |
|    time_elapsed         | 195          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.137393e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.144        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00095     |
|    learning_rate        | 1.19e-05     |
|    loss                 | 11.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -8.54e-06    |
|    value_loss           | 23.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -140.79224    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 5             |
|    time_elapsed         | 246           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.1443855e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.144         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00137       |
|    learning_rate        | 1.19e-05      |
|    loss                 | 12            |
|    n_updates            | 40            |
|    policy_gradient_loss | -9.92e-06     |
|    value_loss           | 24            |
-------------------------------------------
mean_reward
-157.34537
[I 2022-04-25 21:56:33,666] Trial 87 finished with value: -157.34536743164062 and parameters: {'batch_size': 75712, 'gamma': 0.937391961222315, 'learning_rate': 1.1856281470362319e-05, 'clip_range': 0.1441871178349211, 'gae_lambda': 0.9239448135835622}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 28608, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_89
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 796        |
|    ep_rew_mean     | -159.34457 |
| time/              |            |
|    fps             | 518        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 798          |
|    ep_rew_mean          | -157.08151   |
| time/                   |              |
|    fps                  | 507          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 3.152818e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.355        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00177     |
|    learning_rate        | 2.54e-05     |
|    loss                 | 13.7         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.9e-05     |
|    value_loss           | 27.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 825           |
|    ep_rew_mean          | -157.12762    |
| time/                   |               |
|    fps                  | 504           |
|    iterations           | 3             |
|    time_elapsed         | 146           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 1.9886647e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.355         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00138      |
|    learning_rate        | 2.54e-05      |
|    loss                 | 10.6          |
|    n_updates            | 20            |
|    policy_gradient_loss | -2.26e-05     |
|    value_loss           | 21.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 843           |
|    ep_rew_mean          | -163.66972    |
| time/                   |               |
|    fps                  | 499           |
|    iterations           | 4             |
|    time_elapsed         | 196           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.6410438e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.355         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00164      |
|    learning_rate        | 2.54e-05      |
|    loss                 | 10.6          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.17e-05     |
|    value_loss           | 21.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 851           |
|    ep_rew_mean          | -147.36766    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.4100078e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.355         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000813      |
|    learning_rate        | 2.54e-05      |
|    loss                 | 10.7          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.67e-05     |
|    value_loss           | 21.5          |
-------------------------------------------
mean_reward
-193.6234
[I 2022-04-25 22:01:00,157] Trial 88 finished with value: -193.62339782714844 and parameters: {'batch_size': 28608, 'gamma': 0.9286910033100286, 'learning_rate': 2.5391057017359107e-05, 'clip_range': 0.35470227071164967, 'gae_lambda': 0.933158730979425}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 38116, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_90
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 759        |
|    ep_rew_mean     | -157.31143 |
| time/              |            |
|    fps             | 508        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 796          |
|    ep_rew_mean          | -157.46219   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 2            |
|    time_elapsed         | 99           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.804353e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.12         |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00169      |
|    learning_rate        | 1.79e-05     |
|    loss                 | 16.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.82e-05    |
|    value_loss           | 32.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 796           |
|    ep_rew_mean          | -159.32097    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 3             |
|    time_elapsed         | 150           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.8714963e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.12          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000345      |
|    learning_rate        | 1.79e-05      |
|    loss                 | 18.4          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.2e-05      |
|    value_loss           | 36.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 812           |
|    ep_rew_mean          | -154.4899     |
| time/                   |               |
|    fps                  | 495           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.3687276e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.12          |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00329       |
|    learning_rate        | 1.79e-05      |
|    loss                 | 16.4          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.09e-05     |
|    value_loss           | 32.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 824          |
|    ep_rew_mean          | -150.32626   |
| time/                   |              |
|    fps                  | 492          |
|    iterations           | 5            |
|    time_elapsed         | 249          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 3.881481e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.12         |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.000819    |
|    learning_rate        | 1.79e-05     |
|    loss                 | 18.9         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.14e-05    |
|    value_loss           | 37.9         |
------------------------------------------
mean_reward
-140.77135
[I 2022-04-25 22:05:37,630] Trial 89 finished with value: -140.77134704589844 and parameters: {'batch_size': 38116, 'gamma': 0.921983352727835, 'learning_rate': 1.787708247232557e-05, 'clip_range': 0.12019522786712308, 'gae_lambda': 0.9817919825114106}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 25115, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_91
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 890        |
|    ep_rew_mean     | -131.40102 |
| time/              |            |
|    fps             | 529        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 858          |
|    ep_rew_mean          | -144.84212   |
| time/                   |              |
|    fps                  | 511          |
|    iterations           | 2            |
|    time_elapsed         | 96           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 7.254857e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.169        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00218      |
|    learning_rate        | 1.44e-05     |
|    loss                 | 24.1         |
|    n_updates            | 10           |
|    policy_gradient_loss | -2.24e-05    |
|    value_loss           | 48.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 863          |
|    ep_rew_mean          | -148.10657   |
| time/                   |              |
|    fps                  | 508          |
|    iterations           | 3            |
|    time_elapsed         | 144          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 4.125468e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.169        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000968     |
|    learning_rate        | 1.44e-05     |
|    loss                 | 22.5         |
|    n_updates            | 20           |
|    policy_gradient_loss | -8.63e-06    |
|    value_loss           | 45.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 857           |
|    ep_rew_mean          | -149.88385    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.9368191e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.169         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00161       |
|    learning_rate        | 1.44e-05      |
|    loss                 | 23.6          |
|    n_updates            | 30            |
|    policy_gradient_loss | -7.58e-06     |
|    value_loss           | 47.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 844           |
|    ep_rew_mean          | -161.09645    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.7857217e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.169         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00144       |
|    learning_rate        | 1.44e-05      |
|    loss                 | 23.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -7.65e-06     |
|    value_loss           | 46.5          |
-------------------------------------------
mean_reward
-120.947815
[I 2022-04-25 22:10:10,020] Trial 90 finished with value: -120.94781494140625 and parameters: {'batch_size': 25115, 'gamma': 0.9541730775604966, 'learning_rate': 1.4370771011219895e-05, 'clip_range': 0.16929460735233115, 'gae_lambda': 0.9726630666451495}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 26167, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_92
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 796       |
|    ep_rew_mean     | -150.1171 |
| time/              |           |
|    fps             | 519       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 790           |
|    ep_rew_mean          | -147.6515     |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 4.7310703e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00131       |
|    learning_rate        | 1.27e-05      |
|    loss                 | 31.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -1.92e-05     |
|    value_loss           | 63.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 801           |
|    ep_rew_mean          | -155.21385    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.8458697e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000616      |
|    learning_rate        | 1.27e-05      |
|    loss                 | 31            |
|    n_updates            | 20            |
|    policy_gradient_loss | -7.74e-06     |
|    value_loss           | 62.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 824           |
|    ep_rew_mean          | -161.7435     |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.3649289e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00178       |
|    learning_rate        | 1.27e-05      |
|    loss                 | 31.5          |
|    n_updates            | 30            |
|    policy_gradient_loss | -6.78e-06     |
|    value_loss           | 63            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 843           |
|    ep_rew_mean          | -157.53452    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.8890812e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.149         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000105      |
|    learning_rate        | 1.27e-05      |
|    loss                 | 27.9          |
|    n_updates            | 40            |
|    policy_gradient_loss | -5.8e-06      |
|    value_loss           | 56            |
-------------------------------------------
mean_reward
-173.22543
[I 2022-04-25 22:14:45,196] Trial 91 finished with value: -173.22543334960938 and parameters: {'batch_size': 26167, 'gamma': 0.9612030838819571, 'learning_rate': 1.2729726324232515e-05, 'clip_range': 0.1493732967887299, 'gae_lambda': 0.973456262774249}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 22885, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 1691
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_93
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 829        |
|    ep_rew_mean     | -138.01564 |
| time/              |            |
|    fps             | 514        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -144.38942    |
| time/                   |               |
|    fps                  | 503           |
|    iterations           | 2             |
|    time_elapsed         | 97            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0465028e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.175         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00194      |
|    learning_rate        | 1.4e-05       |
|    loss                 | 46.8          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.6e-05      |
|    value_loss           | 94.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 803           |
|    ep_rew_mean          | -145.27487    |
| time/                   |               |
|    fps                  | 493           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.8970684e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.175         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.0016       |
|    learning_rate        | 1.4e-05       |
|    loss                 | 45.5          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.08e-05     |
|    value_loss           | 92.5          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 800          |
|    ep_rew_mean          | -157.88684   |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 4            |
|    time_elapsed         | 198          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 4.362712e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.175        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00207     |
|    learning_rate        | 1.4e-05      |
|    loss                 | 45.7         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.07e-05    |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 825          |
|    ep_rew_mean          | -155.6557    |
| time/                   |              |
|    fps                  | 497          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 3.771248e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.175        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00089     |
|    learning_rate        | 1.4e-05      |
|    loss                 | 44.2         |
|    n_updates            | 40           |
|    policy_gradient_loss | -9.66e-06    |
|    value_loss           | 81.4         |
------------------------------------------
mean_reward
-173.0363
[I 2022-04-25 22:19:16,248] Trial 92 finished with value: -173.0363006591797 and parameters: {'batch_size': 22885, 'gamma': 0.9785710366991327, 'learning_rate': 1.4034570160588176e-05, 'clip_range': 0.17524394464503332, 'gae_lambda': 0.9740406473212632}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 32037, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_94
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 772       |
|    ep_rew_mean     | -172.3138 |
| time/              |           |
|    fps             | 514       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 791           |
|    ep_rew_mean          | -173.47807    |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 7.7632045e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.17          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00274      |
|    learning_rate        | 1.44e-05      |
|    loss                 | 14.1          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.3e-05      |
|    value_loss           | 28.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 800           |
|    ep_rew_mean          | -169.66855    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 4.5894318e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.17          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00519      |
|    learning_rate        | 1.44e-05      |
|    loss                 | 14.8          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.01e-05     |
|    value_loss           | 29.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 800           |
|    ep_rew_mean          | -157.82558    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 4             |
|    time_elapsed         | 199           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.0641076e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.17          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00336      |
|    learning_rate        | 1.44e-05      |
|    loss                 | 17.3          |
|    n_updates            | 30            |
|    policy_gradient_loss | -9.95e-06     |
|    value_loss           | 34.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 801           |
|    ep_rew_mean          | -154.32071    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 5             |
|    time_elapsed         | 250           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.2222793e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.17          |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00192      |
|    learning_rate        | 1.44e-05      |
|    loss                 | 21.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -8.56e-06     |
|    value_loss           | 42.3          |
-------------------------------------------
mean_reward
-139.1272
[I 2022-04-25 22:23:46,842] Trial 93 finished with value: -139.127197265625 and parameters: {'batch_size': 32037, 'gamma': 0.9252566818718313, 'learning_rate': 1.4393996447639935e-05, 'clip_range': 0.16963943608514842, 'gae_lambda': 0.9642801693458684}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 68244, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_95
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 814        |
|    ep_rew_mean     | -144.55766 |
| time/              |            |
|    fps             | 521        |
|    iterations      | 1          |
|    time_elapsed    | 47         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 856           |
|    ep_rew_mean          | -161.62578    |
| time/                   |               |
|    fps                  | 514           |
|    iterations           | 2             |
|    time_elapsed         | 95            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 5.3521944e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.188         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -1.39e-05     |
|    learning_rate        | 1.66e-05      |
|    loss                 | 48.1          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.09e-05     |
|    value_loss           | 96.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 836           |
|    ep_rew_mean          | -156.31194    |
| time/                   |               |
|    fps                  | 506           |
|    iterations           | 3             |
|    time_elapsed         | 145           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 3.6314304e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.188         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000999      |
|    learning_rate        | 1.66e-05      |
|    loss                 | 42            |
|    n_updates            | 20            |
|    policy_gradient_loss | -9.49e-06     |
|    value_loss           | 84.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 834           |
|    ep_rew_mean          | -160.428      |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 4             |
|    time_elapsed         | 197           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 2.9251776e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.188         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00121      |
|    learning_rate        | 1.66e-05      |
|    loss                 | 43.1          |
|    n_updates            | 30            |
|    policy_gradient_loss | -7.59e-06     |
|    value_loss           | 86.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 812           |
|    ep_rew_mean          | -155.81123    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 5             |
|    time_elapsed         | 247           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 2.6377773e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.188         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00134      |
|    learning_rate        | 1.66e-05      |
|    loss                 | 43.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -6.88e-06     |
|    value_loss           | 86.4          |
-------------------------------------------
mean_reward
-152.38394
[I 2022-04-25 22:28:17,555] Trial 94 finished with value: -152.38394165039062 and parameters: {'batch_size': 68244, 'gamma': 0.9719855161010922, 'learning_rate': 1.661930848114167e-05, 'clip_range': 0.18805384950902992, 'gae_lambda': 0.9813865853479877}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 28844, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_96
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 787       |
|    ep_rew_mean     | -145.7103 |
| time/              |           |
|    fps             | 512       |
|    iterations      | 1         |
|    time_elapsed    | 47        |
|    total_timesteps | 24576     |
----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 800           |
|    ep_rew_mean          | -147.46608    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 2             |
|    time_elapsed         | 98            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0000319e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.105         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00123      |
|    learning_rate        | 1.71e-05      |
|    loss                 | 18.7          |
|    n_updates            | 10            |
|    policy_gradient_loss | -2.75e-05     |
|    value_loss           | 37.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 775           |
|    ep_rew_mean          | -148.80887    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 3             |
|    time_elapsed         | 149           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 5.0766783e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.105         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000808     |
|    learning_rate        | 1.71e-05      |
|    loss                 | 18.1          |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.06e-05     |
|    value_loss           | 36.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 788          |
|    ep_rew_mean          | -156.07065   |
| time/                   |              |
|    fps                  | 491          |
|    iterations           | 4            |
|    time_elapsed         | 200          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 3.997411e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.105        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000169     |
|    learning_rate        | 1.71e-05     |
|    loss                 | 27.6         |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.08e-05    |
|    value_loss           | 55.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 791           |
|    ep_rew_mean          | -163.36137    |
| time/                   |               |
|    fps                  | 491           |
|    iterations           | 5             |
|    time_elapsed         | 250           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 4.6495796e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.105         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00106       |
|    learning_rate        | 1.71e-05      |
|    loss                 | 20.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -1.05e-05     |
|    value_loss           | 40.5          |
-------------------------------------------
mean_reward
-176.87546
[I 2022-04-25 22:32:49,515] Trial 95 finished with value: -176.87545776367188 and parameters: {'batch_size': 28844, 'gamma': 0.9933949310227078, 'learning_rate': 1.7116637326328702e-05, 'clip_range': 0.10531383910787351, 'gae_lambda': 0.9133756226514076}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 10426, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 3724
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_97
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 824        |
|    ep_rew_mean     | -163.40923 |
| time/              |            |
|    fps             | 524        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 795          |
|    ep_rew_mean          | -159.4495    |
| time/                   |              |
|    fps                  | 498          |
|    iterations           | 2            |
|    time_elapsed         | 98           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 2.820475e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.134        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00112     |
|    learning_rate        | 1.53e-05     |
|    loss                 | 53.5         |
|    n_updates            | 10           |
|    policy_gradient_loss | -4.41e-05    |
|    value_loss           | 102          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 820           |
|    ep_rew_mean          | -157.35835    |
| time/                   |               |
|    fps                  | 497           |
|    iterations           | 3             |
|    time_elapsed         | 148           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.2248769e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.134         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00129      |
|    learning_rate        | 1.53e-05      |
|    loss                 | 48.7          |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.07e-05     |
|    value_loss           | 103           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 828           |
|    ep_rew_mean          | -155.8122     |
| time/                   |               |
|    fps                  | 494           |
|    iterations           | 4             |
|    time_elapsed         | 198           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 1.7351852e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.134         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.000506     |
|    learning_rate        | 1.53e-05      |
|    loss                 | 43.2          |
|    n_updates            | 30            |
|    policy_gradient_loss | -2.86e-05     |
|    value_loss           | 85            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 827           |
|    ep_rew_mean          | -159.77193    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.3311116e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.134         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00138       |
|    learning_rate        | 1.53e-05      |
|    loss                 | 49.1          |
|    n_updates            | 40            |
|    policy_gradient_loss | -2.34e-05     |
|    value_loss           | 98.2          |
-------------------------------------------
mean_reward
-152.51144
[I 2022-04-25 22:37:25,230] Trial 96 finished with value: -152.51144409179688 and parameters: {'batch_size': 10426, 'gamma': 0.9682407470018176, 'learning_rate': 1.5313833690710583e-05, 'clip_range': 0.1341595313598152, 'gae_lambda': 0.9899264352100502}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 13453, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 11123
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_98
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 851        |
|    ep_rew_mean     | -138.04202 |
| time/              |            |
|    fps             | 534        |
|    iterations      | 1          |
|    time_elapsed    | 45         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 849           |
|    ep_rew_mean          | -156.90012    |
| time/                   |               |
|    fps                  | 510           |
|    iterations           | 2             |
|    time_elapsed         | 96            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.0997207e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00168      |
|    learning_rate        | 3.36e-05      |
|    loss                 | 17.2          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000102     |
|    value_loss           | 34.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 837          |
|    ep_rew_mean          | -149.49892   |
| time/                   |              |
|    fps                  | 502          |
|    iterations           | 3            |
|    time_elapsed         | 146          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 5.585432e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.127        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.00106      |
|    learning_rate        | 3.36e-05     |
|    loss                 | 15           |
|    n_updates            | 20           |
|    policy_gradient_loss | -4.87e-05    |
|    value_loss           | 31.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 830          |
|    ep_rew_mean          | -146.22925   |
| time/                   |              |
|    fps                  | 500          |
|    iterations           | 4            |
|    time_elapsed         | 196          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.163952e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.127        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0.000872     |
|    learning_rate        | 3.36e-05     |
|    loss                 | 15           |
|    n_updates            | 30           |
|    policy_gradient_loss | -6.87e-05    |
|    value_loss           | 31.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 839           |
|    ep_rew_mean          | -146.6043     |
| time/                   |               |
|    fps                  | 501           |
|    iterations           | 5             |
|    time_elapsed         | 245           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 9.3230824e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.127         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.00102       |
|    learning_rate        | 3.36e-05      |
|    loss                 | 18            |
|    n_updates            | 40            |
|    policy_gradient_loss | -6.36e-05     |
|    value_loss           | 36.2          |
-------------------------------------------
mean_reward
-189.49535
[I 2022-04-25 22:41:48,906] Trial 97 finished with value: -189.49534606933594 and parameters: {'batch_size': 13453, 'gamma': 0.9347201142823472, 'learning_rate': 3.357030553716397e-05, 'clip_range': 0.12746884431888145, 'gae_lambda': 0.9610795341870748}. Best is trial 71 with value: -88.24408721923828.
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 20195, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 1 untruncated mini-batches, there will be a truncated mini-batch of size 4381
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
reset
Using cuda device
Logging to ./logs_2/PPO_99
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 790        |
|    ep_rew_mean     | -169.31601 |
| time/              |            |
|    fps             | 510        |
|    iterations      | 1          |
|    time_elapsed    | 48         |
|    total_timesteps | 24576      |
-----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 800          |
|    ep_rew_mean          | -181.15373   |
| time/                   |              |
|    fps                  | 494          |
|    iterations           | 2            |
|    time_elapsed         | 99           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 6.740799e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.138        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00539     |
|    learning_rate        | 2.83e-05     |
|    loss                 | 10.4         |
|    n_updates            | 10           |
|    policy_gradient_loss | -7.86e-05    |
|    value_loss           | 20.8         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 791           |
|    ep_rew_mean          | -171.44814    |
| time/                   |               |
|    fps                  | 489           |
|    iterations           | 3             |
|    time_elapsed         | 150           |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 2.9564717e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.138         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00258      |
|    learning_rate        | 2.83e-05      |
|    loss                 | 9.86          |
|    n_updates            | 20            |
|    policy_gradient_loss | -3.37e-05     |
|    value_loss           | 20.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 797          |
|    ep_rew_mean          | -166.10356   |
| time/                   |              |
|    fps                  | 487          |
|    iterations           | 4            |
|    time_elapsed         | 201          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 4.514422e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.138        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00211     |
|    learning_rate        | 2.83e-05     |
|    loss                 | 10.6         |
|    n_updates            | 30           |
|    policy_gradient_loss | -4.79e-05    |
|    value_loss           | 21.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 822           |
|    ep_rew_mean          | -167.56325    |
| time/                   |               |
|    fps                  | 492           |
|    iterations           | 5             |
|    time_elapsed         | 249           |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 3.8380665e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.138         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00145      |
|    learning_rate        | 2.83e-05      |
|    loss                 | 11.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | -3.93e-05     |
|    value_loss           | 21.5          |
-------------------------------------------
mean_reward
-192.43234
[I 2022-04-25 22:46:31,829] Trial 98 finished with value: -192.43234252929688 and parameters: {'batch_size': 20195, 'gamma': 0.9547952111816416, 'learning_rate': 2.8319329291323028e-05, 'clip_range': 0.13762904501488826, 'gae_lambda': 0.9003241663672445}. Best is trial 71 with value: -88.24408721923828.
reset
Using cuda device
/home/duhuaiyu/anaconda3/envs/pytroch11/lib/python3.6/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 25457, but because the `RolloutBuffer` is of size `n_steps * n_envs = 24576`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 24576
We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.
Info: (n_steps=2048 and n_envs=12)
  f"You have specified a mini-batch size of {batch_size},"
Logging to ./logs_2/PPO_100
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 780        |
|    ep_rew_mean     | -140.05157 |
| time/              |            |
|    fps             | 523        |
|    iterations      | 1          |
|    time_elapsed    | 46         |
|    total_timesteps | 24576      |
-----------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 775           |
|    ep_rew_mean          | -150.30025    |
| time/                   |               |
|    fps                  | 496           |
|    iterations           | 2             |
|    time_elapsed         | 99            |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 1.4181084e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.209         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -0.00231      |
|    learning_rate        | 1.87e-05      |
|    loss                 | 14.4          |
|    n_updates            | 10            |
|    policy_gradient_loss | -3.25e-05     |
|    value_loss           | 28.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 801          |
|    ep_rew_mean          | -154.11746   |
| time/                   |              |
|    fps                  | 495          |
|    iterations           | 3            |
|    time_elapsed         | 148          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 8.074373e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.209        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.00205     |
|    learning_rate        | 1.87e-05     |
|    loss                 | 13.3         |
|    n_updates            | 20           |
|    policy_gradient_loss | -1.38e-05    |
|    value_loss           | 26.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 830           |
|    ep_rew_mean          | -150.79518    |
| time/                   |               |
|    fps                  | 502           |
|    iterations           | 4             |
|    time_elapsed         | 195           |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 6.9558155e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.209         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0.000438      |
|    learning_rate        | 1.87e-05      |
|    loss                 | 15.3          |
|    n_updates            | 30            |
|    policy_gradient_loss | -1.33e-05     |
|    value_loss           | 30.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 848          |
|    ep_rew_mean          | -153.00214   |
| time/                   |              |
|    fps                  | 496          |
|    iterations           | 5            |
|    time_elapsed         | 247          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 7.531587e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.209        |
|    entropy_loss         | -3.89        |
|    explained_variance   | -0.0013      |
|    learning_rate        | 1.87e-05     |
|    loss                 | 13           |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.36e-05    |
|    value_loss           | 26           |
------------------------------------------
mean_reward
-117.90182
best_params:
{'batch_size': 28815, 'gamma': 0.9254533886157719, 'learning_rate': 1.958232389849691e-05, 'clip_range': 0.3991136793393521, 'gae_lambda': 0.9893567426332022}
best_trial:
FrozenTrial(number=71, values=[-88.24408721923828], datetime_start=datetime.datetime(2022, 4, 25, 20, 39, 30, 903081), datetime_complete=datetime.datetime(2022, 4, 25, 20, 43, 57, 272459), params={'batch_size': 28815, 'gamma': 0.9254533886157719, 'learning_rate': 1.958232389849691e-05, 'clip_range': 0.3991136793393521, 'gae_lambda': 0.9893567426332022}, distributions={'batch_size': IntUniformDistribution(high=102400, low=10240, step=1), 'gamma': LogUniformDistribution(high=0.9999, low=0.9), 'learning_rate': LogUniformDistribution(high=0.0001, low=1e-05), 'clip_range': UniformDistribution(high=0.4, low=0.1), 'gae_lambda': UniformDistribution(high=0.99, low=0.8)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=71, state=TrialState.COMPLETE, value=None)
[I 2022-04-25 22:51:01,948] Trial 99 finished with value: -117.90181732177734 and parameters: {'batch_size': 25457, 'gamma': 0.9397253056785425, 'learning_rate': 1.8678661489604462e-05, 'clip_range': 0.20896699398264235, 'gae_lambda': 0.9401728619018818}. Best is trial 71 with value: -88.24408721923828.
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: sol: received nil for 'self' argument (use ':' for accessing member functions, make sure member variables are preceeded by the actual object with '.' syntax)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)
[LUA ERROR] in execute_function: [string "function pipeData() if (math.fmod(tonumber(s:..."]:1: bad argument #1 to 'len' (string expected, got nil)

Process finished with exit code 0
